{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IAB - Hands-on Tutorial for Link Analysis\n",
    "\n",
    "Welcome to IAB - hands-on tutorial for link analysis. \n",
    "In this tutorial, we will study several techniques for link analysis in graphs. \n",
    "This tutorial consists of two sessions and one homework, and each of them will handle the following topic:\n",
    "\n",
    "* **Session 1-1**. Tutorial on PageRank - Part 1 (60 mins)\n",
    "* **Session 1-2**. Tutorial on PageRank - Part 2 (60 mins)\n",
    "* <span style=\"color:blue\">**Session 2**. Tutorial on Topic-specific PageRank (120 mins)</span>\n",
    "* **Homework**. Implementation of HITS\n",
    "\n",
    "We recommend fully understanding the lecture videos related to link analysis (or ranking) models such as PageRank, Topic-specific PageRank, and HITS before entering this tutorial since we will **NOT** explain the theoretical backgrounds on these techniques during the tutorial. \n",
    "We will mainly focus on how to implement the algorithms of those models and how to rank nodes in real-world graphs using those ranking models. \n",
    "\n",
    "The main contributors of this material are as follows:\n",
    "* *Jinhong Jung* (jinhongjung@snu.ac.kr)\n",
    "* *Jun-gi Jang* (elnino4@snu.ac.kr)\n",
    "* *U Kang* (ukang@snu.ac.kr)\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "## Session 3. Tutorial on Topic-specific PageRank (60 mins)\n",
    "In this session, we will explore how to implement PageRank in Python. \n",
    "The main goals of this session are summarized as follows:\n",
    "* **Goal 1.** How to implement Topic-specific PageRank based on sparse matrices using `numpy` and `scipy` in Python\n",
    "* **Goal 2.** To perform a qualitative analysis of the ranking result from Topic-specific PageRank in real-world networks\n",
    "\n",
    "The outline of this session is as follows:\n",
    "* **Step 1.** Review Topic-specific PageRank\n",
    "* **Step 2.** Implement Topic-specific PageRank - the sparse matrix version\n",
    "* **Step 3.** Validate your Topic-specific PageRank implementation\n",
    "* **Step 4.** Qualitative analysis of the ranking result from Topic-specific PageRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Step 1. Review Topic-specific PageRank (a.k.a. Personalized PageRank)\n",
    "\n",
    "In this step, we will review Topic-specific PageRank. \n",
    "Note that Topic-specific PageRank is also known as Personalized PageRank (PPR) or Random Walk with Restart (RWR). \n",
    "As described in the lecture video, the main purpose of Topic-specific PageRank is to obtain a ranking w.r.t. given topics (or seed nodes). \n",
    "Since the ranking result is bias to the given seed nodes, that's why it is called Personalized PageRank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1-1. Mathematical definition of Topic-specific PageRank\n",
    "The mathematical definition of Topic-specific PageRank is very similar to that of PageRank. \n",
    "\n",
    "##### Problem definition of Topic-specific PageRank (Personalized PageRank)\n",
    "* **Input**: adjacency matrix $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ of a graph $G=(V, E)$, teleport probability $\\beta$, and set of seeds $S$\n",
    "* **Output**: the Personalized PageRank (PPR) score vector $\\mathbf{r} \\in \\mathbb{R}^{n}$ such that\n",
    "\n",
    "$$\\mathbf{r} = (1-\\beta)\\mathbf{\\tilde{A}}^{\\top}\\mathbf{r} + \\beta\\mathbf{q}$$\n",
    "\n",
    "- Note that the equation of PPR is the same with that of PageRank except for the query vector $\\mathbf{q}$\n",
    "    - $\\mathbf{q}$ is a query vector where $q_{s}=\\frac{1}{|S|}$ for $s \\in S$. For other node $u$, $q_{u} = 0$.\n",
    "    \n",
    "The definitions of adjacency matrix $\\mathbf{A}$ and row-normalized adjacency matrix $\\mathbf{\\tilde{A}}$ are the same (please see Session 1-1 if you want to check)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Step 2. Implement Topic-specific PageRank - the sparse matrix version\n",
    "\n",
    "We are going to implement the sparse matrix version of Topic-specific PageRank in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2-1. Set up requirements for this tutorial\n",
    "\n",
    "As in the previous sessions, we first import required packages as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import numpy\n",
    "except ImportError:\n",
    "    print(\"numpy is not installed, type pip install numpy\")\n",
    "\n",
    "try:\n",
    "    import scipy\n",
    "except ImportError:\n",
    "    print(\"scipy is not installed, type pip install scipy\")\n",
    "\n",
    "%matplotlib inline\n",
    "try:\n",
    "    import matplotlib\n",
    "except ImportError:\n",
    "    print(\"matplotlib is not installed, type pip install matplotlib\")\n",
    "    \n",
    "try:\n",
    "    import pandas\n",
    "except ImportError:\n",
    "    print(\"pandas is not installed, type pip install pandas\")\n",
    "\n",
    "try:\n",
    "    from IPython.display import display \n",
    "except ImportError:\n",
    "    print(\"ipython is not installed, type pip install ipython\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2-2. Implement the phase for loading the graph dataset\n",
    "In this step, we will implement the phase for loading the graph dataset of the sparse matrix version of Personalized PageRank. \n",
    "We first need to import the following packages for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the below commands restrict the number of computation threads to 1\n",
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\" \n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\" \n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, find\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in Session 1-2, we implement the following function.\n",
    "Note that we do not need to modify the function since the functionality in the version is the same with that of Session 1-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SparsePPR:\n",
    "    def load_graph_dataset(self, data_home, is_undirected=False):\n",
    "        '''\n",
    "        Load the graph dataset from the given directory (data_home)\n",
    "\n",
    "        inputs:\n",
    "            data_home: string\n",
    "                directory path conatining a dataset (edges.tsv, node_labels.tsv)\n",
    "            is_undirected: bool\n",
    "                if the graph is undirected\n",
    "        '''\n",
    "        # Step 1. self file paths from data_home\n",
    "        edge_path = \"{}/edges.tsv\".format(data_home)\n",
    "\n",
    "        \n",
    "        # Step 2. read the list of edges from edge_path\n",
    "        edges = np.loadtxt(edge_path, dtype=int)\n",
    "        n = int(np.amax(edges[:, 0:2])) + 1\n",
    "        \n",
    "        # Step 3. convert the edge list to the weighted adjacency matrix\n",
    "        rows = edges[:, 0]\n",
    "        cols = edges[:, 1]\n",
    "        weights = edges[:, 2]\n",
    "        self.A = csr_matrix((weights, (rows, cols)), shape=(n, n))\n",
    "        if is_undirected == True:\n",
    "            self.A = self.A + self.A.T\n",
    "                \n",
    "        # Step 4. set n (# of nodes) and m (# of edges)\n",
    "        self.n = self.A.shape[0]     # number of nodes\n",
    "        self.m = self.A.nnz          # number of edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SparsePPR(SparsePPR):\n",
    "    def load_node_labels(self, data_home):\n",
    "        '''\n",
    "        Load the node labels from the given directory (data_home)\n",
    "\n",
    "        inputs:\n",
    "            data_home: string\n",
    "                directory path conatining a dataset\n",
    "        '''\n",
    "        label_path = \"{}/node_labels.tsv\".format(data_home)\n",
    "        self.node_labels = pd.read_csv(label_path, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the function is correctly implemented. \n",
    "We will use the small dataset at `./data/small` as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sppr = SparsePPR()\n",
    "sppr.load_graph_dataset('./data/small', is_undirected=False)\n",
    "print(\"The number n of nodes: {}\".format(sppr.n))\n",
    "print(\"The number m of edges: {}\".format(sppr.m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import spdiags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described in Session 1-1, we aim to implement the following operation in this phase: \n",
    "\n",
    "$$\\mathbf{\\tilde{A}} = \\mathbf{D}^{-1}\\mathbf{A}$$\n",
    "\n",
    "Note that the function `normalize` of `SparsePPR` is also the same with that of `SparsePageRank` (Session 1-2).\n",
    "Hence, we use the same code from `SparsePageRank` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SparsePPR(SparsePPR):\n",
    "    def normalize(self):\n",
    "        '''\n",
    "        Perform the row-normalization of the given adjacency matrix\n",
    "\n",
    "        outputs:\n",
    "            nA: np.ndarray (n x n matrix) \n",
    "                the row-normalized adjacency matrix of the given graph\n",
    "            d: np.ndarray (n x 1 vector)\n",
    "                the out-degree vector\n",
    "        '''\n",
    "        d = self.A.sum(axis=1) # since A is csr_matrix, the result of sum() is not a normal vector\n",
    "        d = np.asarray(d).flatten() # to make it vector\n",
    "        \n",
    "        d = np.maximum(d, np.ones(self.n))\n",
    "        invd = 1.0 / d\n",
    "        invD = spdiags(invd, 0, self.n, self.n)\n",
    "        \n",
    "        self.nA = invD.dot(self.A)\n",
    "        self.nAT = self.nA.T\n",
    "\n",
    "        self.out_degrees = d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The debugging of the above function can be performed by using the following codes used in the previous sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sppr = SparsePPR()\n",
    "sppr.load_graph_dataset('./data/small', is_undirected=False)\n",
    "sppr.normalize()\n",
    "\n",
    "# check the sum of each row in the row-normalized matrix nA\n",
    "row_sums = np.asarray(sppr.nA.sum(axis=1)).flatten()\n",
    "for (i, degree, row_sum) in zip(range(sppr.n), sppr.out_degrees, row_sums):\n",
    "    print(\"node: {:2d}, out-degree: {:2d},  row_sum: {:.2f}\".format(i, int(degree), row_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2-4. Implement the iterative phase\n",
    "\n",
    "The implementation of the iterative phase of `SparsePPR` is almost the same of that of `SparsePageRank` except for how to treat a given seed nodes. \n",
    "For brevity, we assume the index of a seed is the range of node index. \n",
    "Also, we will consider the deadend issue as in Session 1-2. \n",
    "Based on those considerations, let's implement the iterative phase of `SparsePPR` using the following algorithm. \n",
    "\n",
    "<img src=\"./images/iterative-algorithm-ppr.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SparsePPR(SparsePPR):\n",
    "    def iterate_PPR(self, seeds, b=0.15, epsilon=1e-9, maxIters=100, handles_deadend=True):\n",
    "        '''\n",
    "        ///Try it yourself!///\n",
    "        Iterate the Personalized PageRank equation to obatin the PageRank score vector\n",
    "        \n",
    "        inputs:\n",
    "            seeds: list\n",
    "                the set of seed nodes\n",
    "            b: float (between 0 and 1)\n",
    "                the teleport probability\n",
    "            epsilon: float\n",
    "                the error tolerance of the iteration\n",
    "            maxIters: int\n",
    "                the maximum number of iterations\n",
    "            handles_deadend: bool\n",
    "                if it handles the deadend issue\n",
    "\n",
    "        outputs:\n",
    "            p: np.ndarray (n x 1 vector)\n",
    "                the final PageRank score vector\n",
    "            residuals: list\n",
    "                the list of residuals over the iteration\n",
    "\n",
    "        '''\n",
    "        p = np.zeros(self.n)           # pagerank score vector\n",
    "        residuals = []                 # set the list for residuals over iterations\n",
    "\n",
    "        pass # TODO: implement Algorithm 1\n",
    "    \n",
    "        return p, residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the implementation is correctly performed. \n",
    "We will briefly check each personalized ranking result using `pandas`. \n",
    "See the following code where a seed node is given. \n",
    "Note that the given seed node should have a high ranking score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def rank_nodes(ranking_scores, topk=-1):\n",
    "    sorted_nodes = np.flipud(np.argsort(ranking_scores))\n",
    "    sorted_scores = ranking_scores[sorted_nodes]\n",
    "    ranking_results = pd.DataFrame()\n",
    "    ranking_results[\"node_id\"] = sorted_nodes\n",
    "    ranking_results[\"score\"] = sorted_scores\n",
    "    \n",
    "    return ranking_results[0:topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sppr = SparsePPR()\n",
    "sppr.load_graph_dataset('./data/small', is_undirected=False)\n",
    "sppr.normalize()\n",
    "\n",
    "seeds = [0]\n",
    "r, _ = sppr.iterate_PPR(seeds, b=0.15, epsilon=1e-9, maxIters=100)\n",
    "print(\"The sum of the PageRank score vector: {:.2f}\".format(np.sum(r)))\n",
    "display(rank_nodes(r, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's provide a set of seeds to compute the personalized ranking w.r.t. the seed set. \n",
    "In this case, each seed node in the set should have a high score compared to other nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seeds = [0, 2, 3]\n",
    "r, _ = sppr.iterate_PPR(seeds, b=0.15, epsilon=1e-9, maxIters=100)\n",
    "print(\"The sum of the PageRank score vector: {:.2f}\".format(np.sum(r)))\n",
    "display(rank_nodes(r, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Step 3. Validate your Topic-specific PageRank implementation\n",
    "\n",
    "We will validate the implementation of Topic-specific PageRank. \n",
    "Since the validation and implementation ways are the same, we do not repeat describing the details on this step (also, you do not need to fill the below cells).\n",
    "Let's run each cell and check the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3-1. Check if the residual monotonically decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 13}) # set the font-size in the figure\n",
    "\n",
    "def plot_residuals(residuals, title):\n",
    "    plt.semilogy(residuals, marker='o', markersize=5)\n",
    "    plt.title(title)\n",
    "    plt.ylim(ymin=1e-10, ymax=1e-0)\n",
    "    plt.ylabel('Residual')\n",
    "    plt.xlabel('# of iterations')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seeds = [0, 2, 3]\n",
    "r, residuals = sppr.iterate_PPR(seeds, b=0.15, epsilon=1e-9, maxIters=100)\n",
    "\n",
    "plot_residuals(residuals, 'Change of Residuals from Personalized PageRank')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3-2. Check if the iterative solution is equal to the exact solution of Personalized PageRank\n",
    "\n",
    "The closed form of the equation of PPR is the same as that of PageRank. \n",
    "Let's see the final closed equation of PPR. \n",
    "\n",
    "$$\n",
    "\\mathbf{r} = \\beta\\left(\\mathbf{I} - (1-\\beta)\\mathbf{\\tilde{A}}^{\\top}\\right)^{-1}\\mathbf{q} \\\\\n",
    "$$\n",
    "\n",
    "To implement the function for the exact solution, we just need to handle the query vector $\\mathbf{q}$ in the previous code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SparsePPR(SparsePPR):\n",
    "    def compute_exact_PPR(self, seeds, b=0.15):\n",
    "        '''\n",
    "        Compute the exact PageRank score vector from the closed form\n",
    "\n",
    "        inputs:\n",
    "            b: float (between 0 and 1)\n",
    "                the teleport probability\n",
    "        outputs:\n",
    "            p: np.ndarray (n x 1 vector)\n",
    "                the final PageRank score vector\n",
    "        '''\n",
    "        q = np.zeros(self.n)\n",
    "        q[seeds] = 1.0/len(seeds)\n",
    "\n",
    "        H = np.eye(self.n) - (1.0 - b)*self.nAT\n",
    "        invH = np.linalg.inv(H)\n",
    "\n",
    "        r = b*(invH.dot(q))\n",
    "\n",
    "        return np.asarray(r).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the error between the exact and iterative solutions of Personalized PageRank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sppr = SparsePPR()\n",
    "sppr.load_graph_dataset('./data/small', is_undirected=False)\n",
    "sppr.normalize()\n",
    "\n",
    "seeds = [0, 2, 3]\n",
    "r_exact = sppr.compute_exact_PPR(seeds, b=0.15)\n",
    "r_iter, _ = sppr.iterate_PPR(seeds, b=0.15, epsilon=1e-9, maxIters=100)\n",
    "\n",
    "error = np.linalg.norm(r_exact - r_iter, 1)\n",
    "print(\"Error between exact and iterative PPR scores: {:e}\".format(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Step 4. Qualitative analysis of the ranking result from Topic-specific PageRank\n",
    "\n",
    "In this step, we will explore a user-item network based on the ranking results of Topic-specific PageRank. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We briefly describe the dataset used in this analysis.\n",
    "The name of the dataset is *movielens-100k* which is an undirected network of movie rating data. \n",
    "Each node represents a *user* or *movie*, and an weighted edge between user $u$ and movie $i$ indicates a rating (the weighted of the edge) that the user rates the movie, which is ranged between $1$ and $5$. \n",
    "The dataset is located at `./data/movielens-100k`. \n",
    "The statistics of the dataset is as follows:\n",
    "\n",
    "| Statistic | Value |\n",
    "| --- | --- |\n",
    "| $n$: the number of nodes | 2,625 |\n",
    "| $m$: the number of edges | 100,000 |\n",
    "| the range of ratings | 1 ~ 5 |\n",
    "| the number of users | 943 |\n",
    "| the number of movies | 1,682 |\n",
    "\n",
    "Also, each user or movie has its attributes. \n",
    "A user has `name`, `gender`, `age` and `job`. \n",
    "A movie has `name` and `genres`. \n",
    "Those attributes are aggregated at one file called `node_labels.tsv` for brevity. \n",
    "Let's load and check the dataset. \n",
    "Note that the graph is undirected "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_home = './data/movielens-100k'\n",
    "sppr = SparsePPR()\n",
    "sppr.load_graph_dataset(data_home, is_undirected=True)\n",
    "sppr.load_node_labels(data_home)\n",
    "\n",
    "print(\"The number n of nodes: {}\".format(sppr.n))\n",
    "print(\"The number m of edges: {}\".format(sppr.m))\n",
    "\n",
    "# print the heads (5) of the node labels\n",
    "print('\\nThe top-5 heads of the node labels:')\n",
    "display(sppr.node_labels.head(5))\n",
    "\n",
    "# print the tails (5) of the node labels\n",
    "print('\\nThe bottom-5 tails of the node labels:')\n",
    "display(sppr.node_labels.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4-1.  Qualitative analysis on a personalized ranking w.r.t. a specific user. \n",
    "\n",
    "Now, we will do a qualitative analysis on a personalized ranking w.r.t. a specific user. \n",
    "Before looking into the personalized ranking, we need to check the user's watch history to figure out characteristics of the user. \n",
    "The following code reports the user's demography information and watch history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SparsePPR(SparsePPR):\n",
    "    def show_user_history(self, user_id):\n",
    "        print(\"user_id: {}, demographic infomration:\".format(user_id))\n",
    "        display(self.node_labels.iloc[[user_id]])\n",
    "        _, movie_ids, ratings = find(self.A[user_id, :])\n",
    "        movie_labels = self.node_labels.iloc[movie_ids]\n",
    "        movie_labels.insert(0, \"rating\", ratings)\n",
    "        print(\"user_id: {}, watch history:\".format(user_id))\n",
    "        movie_labels = movie_labels[[\"node_id\", \"type\", \"name\", \"gender/genres\", \"rating\"]]\n",
    "        display(movie_labels.sort_values(by=[\"rating\"], ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target user's node id is `500`, and his watch history is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_home = \"./data/movielens-100k\"\n",
    "sppr = SparsePPR()\n",
    "sppr.load_graph_dataset(data_home, is_undirected=True)\n",
    "sppr.load_node_labels(data_home);\n",
    "sppr.normalize()\n",
    "\n",
    "sppr.show_user_history(user_id=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seemingly, the user frequently watched (and prefer) `drama`, `comedy`, `romance`, and `thriller` movies. \n",
    "\n",
    "We use the following code to rank nodes regardless of node type (the below codes are from the previous session)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SparsePPR(SparsePPR):\n",
    "    def rank_nodes(self, ranking_scores, topk=-1):\n",
    "        '''\n",
    "        Rank nodes in the order of given ranking scores. \n",
    "        This function reports top-k rankings. \n",
    "\n",
    "        inputs:\n",
    "            ranking_scores: np.ndarray\n",
    "                ranking score vector\n",
    "            topk: int\n",
    "                top-k ranking parameter, default is -1 indicating report all ranks\n",
    "        '''\n",
    "        sorted_nodes = np.flipud(np.argsort(ranking_scores)) # argsort in the descending order\n",
    "        sorted_scores = ranking_scores[sorted_nodes]         # sort the ranking scores\n",
    "        ranks = range(1, self.n+1) # 0~n-1\n",
    "\n",
    "        result_labels = self.node_labels.iloc[sorted_nodes][0:topk]\n",
    "        result_labels.insert(0, \"rank\", ranks[0:topk])\n",
    "        result_labels[\"score\"] = sorted_scores[0:topk]\n",
    "        result_labels.reset_index(drop = True, inplace = True)\n",
    "        return result_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the function on a personalized ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_home = \"./data/movielens-100k\"\n",
    "sppr = SparsePPR()\n",
    "sppr.load_graph_dataset(data_home, is_undirected=True)\n",
    "sppr.load_node_labels(data_home);\n",
    "sppr.normalize()\n",
    "\n",
    "seeds = [500]\n",
    "r, _ = sppr.iterate_PPR(seeds, b=0.15, epsilon=1e-9, maxIters=1000)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "display(sppr.rank_nodes(r, topk=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the table, this ranking result contains nodes of movies as well as those of users. For better analysis, we need to implement such reporting functions according to node type. First, we implement rank_users which reports ranking results for only users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SparsePPR(SparsePPR):\n",
    "    def rank_users(self, ranking_scores, topk=-1):\n",
    "        user_labels = self.node_labels[self.node_labels.type == \"user\"]\n",
    "        user_node_ids = user_labels[\"node_id\"].values\n",
    "        user_ranking_scores = ranking_scores[user_node_ids]\n",
    "\n",
    "        sorted_indices = np.flipud(np.argsort(user_ranking_scores))\n",
    "        sorted_users = user_node_ids[sorted_indices]\n",
    "        sorted_scores = user_ranking_scores[sorted_indices]\n",
    "        ranks = range(1, len(user_node_ids)+1)\n",
    "\n",
    "        result_labels = self.node_labels.iloc[sorted_users][0:topk]\n",
    "        result_labels.insert(0, \"rank\", ranks[0:topk])\n",
    "        result_labels[\"score\"] = sorted_scores[0:topk]\n",
    "        result_labels.reset_index(drop = True, inplace = True)\n",
    "        return result_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the example of the result from the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_home = \"./data/movielens-100k\"\n",
    "sppr = SparsePPR()\n",
    "sppr.load_graph_dataset(data_home, is_undirected=True)\n",
    "sppr.load_node_labels(data_home);\n",
    "sppr.normalize()\n",
    "\n",
    "seeds = [500]\n",
    "r, _ = sppr.iterate_PPR(seeds, b=0.15, epsilon=1e-9, maxIters=100)\n",
    "display(sppr.rank_users(r, topk=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the table, there are many students in the top-$10$ ranking list. \n",
    "Note that the querying user ($500$, emil) is also a student. \n",
    "These results imply that the personalized ranking on the user is able to capture other users having the similar preference to the querying user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we see `rank_movies` function which reports ranking results for only movies. \n",
    "Since the implementation is a little complex, we provide the full implementation of the function. \n",
    "This function additionally considers `seeds` and `shows_unseen` arguments since we sometimes want to recommend movies unseen by a user or users. \n",
    "Suppose `seeds` indicate user node ids.\n",
    "If `shows_unseen` is `True`, then the function reports the ranking result for only unseen movies. \n",
    "Otherwise, it will consider all movies to rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "class SparsePPR(SparsePPR):\n",
    "    def rank_movies(self, seeds, ranking_scores, topk=-1, shows_unseen=True):\n",
    "        movie_labels = self.node_labels.loc[self.node_labels[\"type\"] == \"movie\"]\n",
    "        movie_node_ids = movie_labels[\"node_id\"].values\n",
    "        movie_ranking_scores = ranking_scores[movie_node_ids]\n",
    "        \n",
    "        _, seen_movie_ids, _ = find(self.A[seeds, :])\n",
    "        seen_movie_ids = np.unique(seen_movie_ids)\n",
    "        masks = [movie_node_ids == seen_movie for seen_movie in seen_movie_ids]\n",
    "        seen_mask = reduce(np.logical_or, masks)\n",
    "\n",
    "        sorted_indices = np.flipud(np.argsort(movie_ranking_scores))\n",
    "        sorted_movies = movie_node_ids[sorted_indices]\n",
    "        sorted_scores = movie_ranking_scores[sorted_indices]\n",
    "        sorted_seen_mask = seen_mask[sorted_indices]\n",
    "        ranks = range(1, len(movie_node_ids)+1)\n",
    "\n",
    "        result_labels = self.node_labels.iloc[sorted_movies]\n",
    "        result_labels.insert(0, \"rank\", ranks)\n",
    "        result_labels.insert(0, \"score\", sorted_scores)\n",
    "        result_labels.insert(0, \"seen\", sorted_seen_mask)\n",
    "        \n",
    "        if shows_unseen:\n",
    "            result_labels = result_labels.loc[result_labels[\"seen\"] == False]\n",
    "            result_labels[\"rank\"] = range(1, result_labels.shape[0]+1)\n",
    "                \n",
    "        result_labels = result_labels[0:topk]\n",
    "        result_labels.reset_index(drop = True, inplace = True)\n",
    "        return result_labels[[\"rank\", \"node_id\", \"type\", \"name\", \"gender/genres\", \"seen\", \"score\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the example of the result from the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_home = \"./data/movielens-100k\"\n",
    "sppr = SparsePPR()\n",
    "sppr.load_graph_dataset(data_home, is_undirected=True)\n",
    "sppr.load_node_labels(data_home);\n",
    "sppr.normalize()\n",
    "\n",
    "seeds = [500]\n",
    "r, _ = sppr.iterate_PPR(seeds, b=0.15, epsilon=1e-9, maxIters=100)\n",
    "display(sppr.rank_movies(seeds, r, topk=20, shows_unseen=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the querying user frequently watched `drama`, `comedy`, `romance`, and `thriller` movies. \n",
    "Also, there are many such kinds of movies in the recommendation list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Session 2. Summary\n",
    "\n",
    "In this session, we implemented Topic-specific PageRank (the sparse matrix version) in Python. \n",
    "More specifically, we are able to answer the following goals now. \n",
    "\n",
    "* **Goal 1.** How to implement Topic-specific PageRank based on sparse matrices using `numpy` and `scipy` in Python\n",
    "    - We implemented the iterative algorithm for Topic-specific PageRank based on sparse matrices.\n",
    "* **Goal 2.** To perform a qualitative analysis of the ranking result from Topic-specific PageRank in real-world networks\n",
    "    - We performed a qualitative analysis on the `movielens-100k` dataset which is a real-world network. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
