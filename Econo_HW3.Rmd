---
title: "Econometric_HW3"
output:
  word_document: default
  html_document: default
---
### C1
 
(1)  
Var(u|totwrk,educ,age,yngkid,male)  
= Var(u|male) = a0+a1male   
만일 여성이면 male = 0이고 var(u|male=0) = a0  
만일 남성이면 male = 1이고 var(u|male=1) = a0+a1  

(2)  

```{r}
library(wooldridge)
data('sleep75')
```

```{r}
model = lm(sleep~totwrk+educ+age+agesq+yngkid+male, data = sleep75)
```

```{r}
male = sleep75$male == 1
```

```{r}
sd(model$fitted.values[male])
```
```{r}
sd(model$fitted.values[!male])
```
여성의 분산이 더 높다. 

(3) 분산 검정. 

```{r}
x = model$fitted.values[!male] 
y = model$fitted.values[male]

var.test(x, y, ratio=1, alternative="two.sided", conf.level=0.95)
```

등분산 검정 결과 F값이 1.03로 상당히 낮고, p-value가 0.77로 높다. 따라서 신뢰수준 95%에서 귀무가설을 기각할 충분한 증거가 없으며 두 집단의 분산은 유의미하게 다르지 않다. 

### C2

(1)

```{r}
data("hprice1")
library(sandwich)
OLS = lm(price~lotsize+sqrft+bdrms, data = hprice1)

library(lmtest)
coeftest(OLS,vcov=vcovHC(OLS,type = 'HC0'))
```
```{r}
coeftest(OLS)
```

일반적인 모델과 비교했을 때, 가장 큰 차이가 나는 변수는 lotsize이다. 강건한 모델에서는 lotsize의 표준오차가 거의 2배이상 증가하였고, 이로 인해 t-value값이 줄어들어 강건한 모델에서는 lotsize를 유의미하다고 보기 어려워졌다.(sqrft는 두 모델에서 유의미하고 bdrms는 두 모델에서 모두 유의미하지 않다.) 

(2)

```{r}

OLS = lm(log(price)~log(lotsize)+log(sqrft)+bdrms, data = hprice1)
coeftest(OLS,vcov=vcovHC(OLS,type = 'HC0'))
```

```{r}
coeftest(OLS)
```

여전히 견고한 모델의 표준오차가 더 높은 편이지만, 그 전과 달리 log를 한 모델에서는 lotsize변수가 강건한 모델에서도 유의미하다. 

(3)
독립변수에 대해 적절한 변환을 사용하면 이분산성을 완화할 수 있다. 

### C3

```{r}
yhat = OLS$fitted
u2 = OLS$residuals^2
Ru2 = summary(lm(u2 ~ yhat + I(yhat^2)))$r.squared
LM = nrow(hprice1)*Ru2
p.value = 1-pchisq(LM, 2)
print(LM)
p.value
```

LM통계량이 3.447287 정도로 나오며, p-value가 0.178로 homoskedasticity assumption을 기각하기 어렵다. 따라서 8.18식에 따른 모델의 경우, 오차항의 등분산성을 가정할 수 있다. 

### C4

(1)

```{r}
data(vote1)
OLS = lm(voteA~prtystrA+democA+log(expendA)+log(expendB), data = vote1)
```

```{r}
u = OLS$residuals
OLS2 = lm(u~prtystrA+democA+log(expendA)+log(expendB), data = vote1)
summary(OLS2)$r.squared
```

OLS를 통해 나온 잔차는 독립변수들이 span하는 열공간에 직교하기 때문에 잔차를 독립변수가 span하는 열공간에 projection하면 그 자신이 되기 때문에 설명되는 부분이 없고 R2값도 0이다. 다만 컴퓨터의 rounding error 때문에 정확히 0은 아니다. 

(2)

```{r}
bptest(voteA~prtystrA+democA+log(expendA)+log(expendB),~prtystrA+democA+log(expendA)+log(expendB),data=vote1)
```

test결과 유의확률이 0.058정도로 유의수준 5%이내에서 유의미하지 않다. 따라서 귀무가설을 기각할만한 충분한 근거고 등분산성을 가정할 수 있으나 유의확률이 유의수준에 거의 근접하기 때문에 유의수준을 어떻게 설정하는 지에 따라서 이분산성에 대한 유의미한 증거가 될 수 있다. 

(3)

```{r}
yhat = OLS$fitted
u2 = OLS$residuals^2
white = lm(u2~yhat+I(yhat^2))
summary(white)
```
F통계량(2,170)은 2.786이고 p-value는 0.0645정도로 (2)보다 유의확률이 더 높아졌다. 따라서 (2)와 마찬가지로 유의수준 5%에서는 기각이 어렵다. 

### C8

(1)
```{r}
data('GPA1')
OLS = lm(colGPA~hsGPA+ACT+skipped+PC, data = gpa1)
u = OLS$residuals
summary(OLS)
```

(2)
```{r}
yhat = OLS$fitted
u2 = OLS$residuals^2
white = lm(u2~yhat+I(yhat^2))
summary(white)
```
F 통계량 값이 3.581 정도이고 유의확률은 0.03정도로 유의수준 5%에서 귀무가설을 기각할 수 있는 충분한 증거가 있다. 따라서 이분산성이 존재한다고 할 수 있다.  

(3)
```{r}
hhat = white$fitted

min(hhat)
```
최소값이 0.027이므로 모든 값이 양수이다. 

```{r}
WLS = lm(colGPA~hsGPA+ACT+skipped+PC, data = gpa1,,weights=(1/hhat))
```

```{r}
summary(WLS)
```
PC 변수의 회귀계수 값이 조금 높아졌지만 큰 차이는 없다.  두 모델의 t 통계량이 거의 유사하다. R2의 경우, WLS에서 0.04정도 상승해지면, 전반적으로 큰 변화는 아니어서 두 모델이 유의미하게 다르다고 말하기 어렵다. 

(4)

```{r}
coeftest(WLS,vcov=vcovHC(WLS,type = 'HC0'))
```
```{r}
coeftest(WLS)
```

robust standard errors를 사용했을 때와 그렇지 않았을 때의 결과가 크게 다르지 않다. robust standard errors를 사용했을 때, 전반적으로 표준오차가 커진 경향이 있지만 매우 작아서 두 모델의 결과를 유의미하게 바꾸지 않는다.

### C9

(1)
```{r}
data("smoke")

OLS = lm(cigs~log(income)+log(cigpric)+educ+age+agesq+restaurn, data = smoke)

summary(OLS)
```
OLS 추정결과, F통계량이 유의미하고 educ,age,agesq,restaurn 변수가 유의미하게 나온다. 하지만 R2 값 자체는 매우 낮은 편이다. 

```{r}
RegModel = cigs~log(income)+log(cigpric)+educ+age+agesq+restaurn
OLS = lm(RegModel,data = smoke)
smoke$e = OLS$residuals
AUX = lm(update(OLS,I(log(e^2))~.), data = smoke)
smoke$ghat = AUX$fitted
smoke$hhat = exp(smoke$ghat)
FGLS = lm(RegModel,data=smoke,weights = 1/hhat)
summary(FGLS)
```
```{r}
head(FGLS$residuals) 
head(OLS$residuals)
```
두 잔차간의 차이가  있긴 하지만, 그렇게 크진 않다.  

```{r}
uhat = FGLS$residuals
yhat = FGLS$fitted
```

(3)
```{r}
u2 = uhat/sqrt(hhat)
y2 = yhat/sqrt(hhat)
```

```{r}
white = lm((u2)^2~y2+I(y2^2))
summary(white)
```
R2 값은 0.027로 낮은 수치지만, F-통계량이 상당히 높고 p-value가 0에 수렴한다. 특히 I(y2^2)변수가 유의미한 값이 나온다. 이를 통해 오차와 독립변수의 함수관계가 없다는 귀무가설을 기각할 만한 충분한 증거를 확인할  수 있으며, 오차와 독립변수 사이에 함수관계가 있다고 볼 수 있다. 또한 오차와 독립변수 사이에 함수 관계가 있다면 이를 이분산성으로 간즈 할 수 있다.  

(4)

3번 문제에서 확인할 수 있듯이 FGSL가 이분산성을 제거하지 않는다는 것을 알 수 있다.따라서 일반적인 검정에 사용되는 통계량을 그대로 사용할 수 없고 지금 출력된 그 결과도 유효하지 않다. (검정통계량들이 등분산을 가정하고 만들어졌기 때문에 이분산성이 있다면 이를 조정한 통계량을 사용해야한다.)

(5)

```{r}
coeftest(FGLS, vcov = vcovHC(FGLS,type = 'HC0'))
```

```{r}
coeftest(FGLS)
```
통계량을 보정한 결과, 해석을 유의미하게 바꿀 변화는 관측되지 않는다. 하지만 restaurn를 제외하고 모든 추정량의 표준오차가 늘어난 것을 확인할 수 있다. 특히 log(cigpric)은 두배 가까이 표준오차가 증가했다. 


### C12

(1)

```{r}
data("meap00_01")
OLS = lm(math4~lunch+log(enroll)+log(exppp), data = meap00_01)
coeftest(OLS)
```


```{r}
coeftest(OLS, vcov = vcovHC(OLS,type = 'HC0'))
coeftest(OLS, vcov = vcovHC(OLS,type = 'HC1'))
coeftest(OLS, vcov = vcovHC(OLS,type = 'HC2'))
coeftest(OLS, vcov = vcovHC(OLS,type = 'HC3'))
coeftest(OLS, vcov = vcovHC(OLS,type = 'HC4'))
```

어떠한 경우라도 heteroskedasticity-robust한 모델의 표준오차가 OLS 모델보다 언제나 다소 크다. 

(2)

```{r}
yhat = OLS$fitted
u2 = OLS$residuals^2
white = lm(u2~yhat+I(yhat^2))
summary(white)
```
F 통계량이 132.7로 상당히 높고 유의확률이 0에 수렴한다. 따라서 이분산성에 대한 강한 증거가 존재한다고 볼 수 있다. 

(3)

```{r}
math4hat = OLS$fitted
uhat = OLS$residuals

ghat = lm(log(uhat^2)~math4hat+I(math4hat^2))$fitted
hhat =exp(ghat)

WLS = lm(math4~lunch+log(enroll)+log(exppp),data = meap00_01,weights = 1/hhat)
coeftest(WLS)
```
```{r}
coeftest(OLS)
```
lunch 변수는 두 모델 모두 유의미하고 계수의 크기도 거의 유사하다. log(enroll)은 OLS,WLS모두 유의미하지만 WLS 2.7 정도 증가했다. 가장 큰 변화는 log(exppp)인데, OLS 추정에는 유의미하지 않지만, WLS 추정에서는 유의미해진다.  

(4)

```{r}
coeftest(WLS, vcov = vcovHC(WLS,type = 'HC0'))
```
(3)에서 WLS추정에서 유의미한 결과를 강건한 표준오차를 기반한 통계량으로 다시 계산해볼 필요가 있다. 가장 특징적인 변화를 보였던 log(exppp)변수의 경우, 표준오차값이 다소 증가했지만 여전히 유의미하다. 다른 변수도 표준오차 값이 전보다 증가하거나 비슷하지만 여전히 유의미하다.  

(5)
WLS 추정이 OLS보다 정확하다. WLS 추정의 log(exppp)의 강건한 표준오차는 1.8로 OLS의 경우(2.09) 보다 작다. 추정량의 표준오차가 더 작을수록 effiecncy가 좋은 추정이라고 할 수 있으며, t값도 훨씬 줄어들기 때문에 보다 유의미해진다. 

### CHAPTER 10

### C7 - (1)

```{r}
data("consump")

OLS = lm(consump$gc~consump$gy)
summary(OLS)
```
gc = 0.008079 + 0.570781gy n = 35 R2 = 0.6787  
회귀 분석 결과, 소득의 상승률이 1퍼센트 포인트 오르다면 소비 상승률이 0.571퍼센트 포인트 가량 오른다고 볼 수 있다.   
gy변수의 t값이 8.5정도롤 높기 떄문에 추정량이 유의미하다.   

### CHAPTER 12

### C6 - (1)
