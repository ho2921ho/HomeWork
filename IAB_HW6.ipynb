{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[IAB]_20190531_RNN_(Students).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "s97fwEOoiXk3"
      ]
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UwlPAA8ZJUsr"
      },
      "source": [
        "Copyright (C) 2019 Software Platform Lab, Seoul National University\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); \n",
        "\n",
        "you may not use this file except in compliance with the License. \n",
        "\n",
        "You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 \n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software \n",
        "\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS, \n",
        "\n",
        "\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \n",
        "\n",
        "\n",
        "See the License for the specific language governing permissions and\n",
        "\n",
        "\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ki_RHIwPJvyn"
      },
      "source": [
        "#1. Recap on TF basics\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iYjV1h5ZDswF"
      },
      "source": [
        "## 1) Graph and Session\n",
        "* **Graph** : It contains a set of Operations (units of computation) and Tensors (units of data between operations).\n",
        "\n",
        "* **Session** : It encapsulates an execution environment such as which operations are executed and what is the current values of Tensor objects. \n",
        "\n",
        "Let's learn Graph and Session using examples presented below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pz2yv_VJ-Nqe"
      },
      "source": [
        "## 2) Constant Op\n",
        "\n",
        "Let's create a constant in TensorFlow.\n",
        "\n",
        "**```tf.constant(value, dtype = None, shape = None, name = 'Const', verify_shape = False)```**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "67YpM6V5-bPN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "db847492-41af-4f35-e5e2-36539226b2ec"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "  #constant of 1d tensor, or a vector\n",
        "  a = tf.constant([2,2], name = 'vector')\n",
        "\n",
        "  #constant of 2x2 tensor, or a matrix\n",
        "  b = tf.constant([[0,2], [1,3]], name = 'matrix')\n",
        "\n",
        "print(a)\n",
        "print(b)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"vector:0\", shape=(2,), dtype=int32)\n",
            "Tensor(\"matrix:0\", shape=(2, 2), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XTmGAV29-eHq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "55cc26f0-cd3b-4bb8-bde7-8259716218bf"
      },
      "source": [
        "# Get values of a and b\n",
        "with tf.Session(graph=graph) as sess:\n",
        "  print('a')\n",
        "  print(sess.run(a))\n",
        "  print('b')\n",
        "  print(sess.run(b))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a\n",
            "[2 2]\n",
            "b\n",
            "[[0 2]\n",
            " [1 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MK1o9cMo-ir-"
      },
      "source": [
        "## 3) Math Ops\n",
        "TensorFlow math ops are pretty standard. The following example shows a matrix division op."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e_h71-SU-lD-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "c47f0122-2dd6-491d-8b7e-e53ffefee172"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "  # Create constant a and b\n",
        "  a = tf.constant([2,2], name = 'a', dtype = tf.float32)\n",
        "  b = tf.constant([[0,1], [2,3]], name = 'b', dtype = tf.float32)\n",
        "  \n",
        "  # Create divide operation using b and a\n",
        "  div = tf.div(b, a)\n",
        "\n",
        "print('Print information of div op')\n",
        "print(div.op)\n",
        "\n",
        "print('\\nPrint div')\n",
        "print(div)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-c519994a35ee>:10: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Print information of div op\n",
            "name: \"div\"\n",
            "op: \"RealDiv\"\n",
            "input: \"b\"\n",
            "input: \"a\"\n",
            "attr {\n",
            "  key: \"T\"\n",
            "  value {\n",
            "    type: DT_FLOAT\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "Print div\n",
            "Tensor(\"div:0\", shape=(2, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6s2cqiK5-rXt"
      },
      "source": [
        "Run div operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lU70raMp-sHk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "6bba73bf-db5c-4885-8c25-1aad1edae55c"
      },
      "source": [
        "with tf.Session(graph=graph) as sess:\n",
        "  print('Print div.op')\n",
        "  print(sess.run(div.op))\n",
        "  \n",
        "  print('\\nPrint div')\n",
        "  print(sess.run(div))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Print div.op\n",
            "None\n",
            "\n",
            "Print div\n",
            "[[0.  0.5]\n",
            " [1.  1.5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "33Jpl4SO-1ai"
      },
      "source": [
        "## 4) Variables\n",
        "\n",
        "TensorFlow object to store mutable data (e.g., model parameters)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wjis-ubA_GCQ"
      },
      "source": [
        "We can create variables using **`tf.get_variable`**, which allows us to provide the variable's internal name, shape, type, and initializer to give the variable its initial value.\n",
        "\n",
        "```\n",
        "tf.get_variable(\n",
        "    name,\n",
        "    shape=None,\n",
        "    dtype=None,\n",
        "    initializer=None,\n",
        "    regularizer=None,\n",
        "    trainable=True,\n",
        "    collections=None,\n",
        "    caching_device=None,\n",
        "    partitioner=None,\n",
        "    validate_shape=True,\n",
        "    use_resource=None,\n",
        "    custom_getter=None,\n",
        "    constraint=None\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oam6UNCp_K7y"
      },
      "source": [
        "Create three variables using `tf.get_variable`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6YxVm9_z_J2X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "9af6e6e1-bf62-4265-85a4-20bfa9e1634a"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "  s = tf.get_variable('scalar', initializer=tf.constant(2))\n",
        "  m = tf.get_variable('matrix', initializer=tf.constant([[0,1], [2,3]]))\n",
        "  B = tf.get_variable('big_matrix', shape=(784, 10), initializer=tf.zeros_initializer())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "feAclxjz_ORv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "7f2d5625-9f7e-43e4-b527-d72af4b868f7"
      },
      "source": [
        "with tf.Session(graph=graph) as sess:\n",
        "  print(sess.run(s)) # [SPOILER] Don't get scared even you encounter an error"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FailedPreconditionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value scalar\n\t [[{{node _retval_scalar_0_0}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-f5e0a778f287>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [SPOILER] Don't get scared even you encounter an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value scalar\n\t [[{{node _retval_scalar_0_0}}]]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eDnhU-Q__TFj"
      },
      "source": [
        "### Initialize variables\n",
        "\n",
        "Before using a variable, you must initialize it, or else you'll run into an error.\n",
        "\n",
        "To initiliaze them all at once: use **`tf.global_variables_initializer()`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iS5zTCyq_OPn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "9c8a7ff0-a142-4df3-d06d-8492dcf070db"
      },
      "source": [
        "with tf.Session(graph=graph) as sess:\n",
        "  # Initialize variables\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  print('print s')\n",
        "  print(sess.run(s))\n",
        "  print('\\nprint m')\n",
        "  print(sess.run(m))\n",
        "  print('\\nprint B')\n",
        "  print(sess.run(B))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "print s\n",
            "2\n",
            "\n",
            "print m\n",
            "[[0 1]\n",
            " [2 3]]\n",
            "\n",
            "print B\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LnDXZ0Ve_XA5"
      },
      "source": [
        "### Evaluate values of variables\n",
        "\n",
        "To get the value of a variable, we need to fetch it within a session.\n",
        "\n",
        "This example shows how to evaluate the value (`sess.run` and `eval`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ntc6ZW8o_J4w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "outputId": "14dcef14-108c-4567-e4a6-6512a7610834"
      },
      "source": [
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "  # v is a 784 x 10 variable of random values\n",
        "  v = tf.get_variable('normal_matrix', shape=(784,10), initializer=tf.truncated_normal_initializer())\n",
        "\n",
        "with tf.Session(graph=graph) as sess:\n",
        "  # Initialize variables\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  \n",
        "  # Get value with sess.run()\n",
        "  v_sess = sess.run(v)\n",
        "  print('v value with sess.run')\n",
        "  print(v_sess)\n",
        "\n",
        "  # Get value with v.eval()\n",
        "  v_eval = v.eval()\n",
        "  print('\\nv value with v.eval()')\n",
        "  print(v_eval)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "v value with sess.run\n",
            "[[-1.1046802   1.3352509   0.60328496 ... -0.68056965  0.52782935\n",
            "  -0.20416825]\n",
            " [-0.43662754 -0.24992189 -0.28197387 ...  0.6746541   0.11988721\n",
            "  -0.8294989 ]\n",
            " [ 0.6119669   0.6092383  -1.0912067  ...  0.39604026 -0.46768284\n",
            "   1.3149389 ]\n",
            " ...\n",
            " [-0.08623898  0.71242857  0.8068247  ...  0.8159966  -0.427081\n",
            "   0.38499048]\n",
            " [ 1.1006298  -0.71694905 -0.11410499 ...  1.5929395  -0.4554197\n",
            "  -1.1927482 ]\n",
            " [ 1.394731   -0.07344379 -1.0126097  ...  1.251117   -0.8205014\n",
            "   0.5391605 ]]\n",
            "\n",
            "v value with v.eval()\n",
            "[[-1.1046802   1.3352509   0.60328496 ... -0.68056965  0.52782935\n",
            "  -0.20416825]\n",
            " [-0.43662754 -0.24992189 -0.28197387 ...  0.6746541   0.11988721\n",
            "  -0.8294989 ]\n",
            " [ 0.6119669   0.6092383  -1.0912067  ...  0.39604026 -0.46768284\n",
            "   1.3149389 ]\n",
            " ...\n",
            " [-0.08623898  0.71242857  0.8068247  ...  0.8159966  -0.427081\n",
            "   0.38499048]\n",
            " [ 1.1006298  -0.71694905 -0.11410499 ...  1.5929395  -0.4554197\n",
            "  -1.1927482 ]\n",
            " [ 1.394731   -0.07344379 -1.0126097  ...  1.251117   -0.8205014\n",
            "   0.5391605 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WOn6Dyg5_eto"
      },
      "source": [
        "To change the values of variables, use `tf.assign`.\n",
        "\n",
        "You can see variable v changes after an *assign* operation is executed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f6dZT-Bk_cPx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "83a9643f-0c80-4ee5-cfb3-495d960bd442"
      },
      "source": [
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "  # Create variable v.\n",
        "  v = tf.get_variable(\"a\", shape=(2), initializer=tf.ones_initializer())\n",
        "  \n",
        "  # Create two assign operations.\n",
        "  assign_2 = tf.assign(v, [2, 2])\n",
        "  assign_5 = tf.assign(v, [5, 5])\n",
        "  \n",
        "with tf.Session(graph=graph) as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  \n",
        "  # Before applying assign op.\n",
        "  v_val = sess.run(v)\n",
        "  print('Initial value: %s' % (v_val))\n",
        "  \n",
        "  # Run assign_2\n",
        "  sess.run(assign_2)\n",
        "  print('After assign_2: %s' % sess.run(v))\n",
        "  \n",
        "  # Run assign_5\n",
        "  sess.run(assign_5)\n",
        "  print('After assign_5: %s' % sess.run(v))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial value: [1. 1.]\n",
            "After assign_2: [2. 2.]\n",
            "After assign_5: [5. 5.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1lZIuOlC9LhB"
      },
      "source": [
        "## 5) Let's train a simple model using MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l9itTzW1Jvzr"
      },
      "source": [
        "### A. Prepare MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Mil88Pi19Ys0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "outputId": "21b89917-cbf2-4551-916b-17a814089331"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "                                  \n",
        "graph = tf.Graph()\n",
        "with graph.as_default():\n",
        "  x = tf.placeholder(tf.float32, [None, 784])\n",
        "  y = tf.placeholder(tf.float32, [None, 10])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-10-8e442db1cfc8>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GApqxder9b8B"
      },
      "source": [
        "### B. Create weights and bias\n",
        "w is initialized to random normal distribution variables with mean 0 and standard deviation 0.01. b is initialized to 0's. The shape of w depends on the dimensions of X and Y so that Y = tf.matmul(X,w). The shape of b depends on Y."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sLBg4g8n9eue",
        "colab": {}
      },
      "source": [
        "with graph.as_default():\n",
        "  W = tf.get_variable(name='weights', shape=[784, 10], initializer=tf.random_normal_initializer(0, 0.01))\n",
        "  b = tf.get_variable(name='bias', shape=[10], initializer=tf.zeros_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Bw96XRvA-_bu"
      },
      "source": [
        "### C. Define a loss function\n",
        "\n",
        "The cross entropy of softmax of logits is our loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2ipngj0g_BrG",
        "colab": {}
      },
      "source": [
        "with graph.as_default():\n",
        "  logits = tf.matmul(x, W) + b\n",
        "  entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y, name='entropy')\n",
        "  loss = tf.reduce_mean(entropy, name='loss') # average over all the examples in the batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B4jwUlGF_Urd"
      },
      "source": [
        "### D. Define a training op\n",
        "\n",
        "We'll use an Adam optimizer with a learning rate of 0.01 to minimize loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RX1AIa5Y_VTq",
        "colab": {}
      },
      "source": [
        "with graph.as_default():\n",
        "  optimizer = tf.train.AdamOptimizer(0.01)\n",
        "  train_op = optimizer.minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kqZJMz4B_Yqz"
      },
      "source": [
        "### E. Train the model\n",
        "\n",
        "Finally, we train the model and see how the training loss decreases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RM--FoSO_ZYQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "56da14ef-679f-48e4-8146-65f42d784b36"
      },
      "source": [
        "with tf.Session(graph=graph) as sess:\n",
        "  init = tf.global_variables_initializer()\n",
        "  sess.run(init)\n",
        "\n",
        "  for i in range(1000):\n",
        "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
        "    _, loss_ = sess.run([train_op, loss], feed_dict={x: batch_xs, y: batch_ys})\n",
        "    if i % 50 == 0:\n",
        "      print('Step:', i, '  Loss:', loss_)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step: 0   Loss: 2.2827573\n",
            "Step: 50   Loss: 0.451783\n",
            "Step: 100   Loss: 0.27187717\n",
            "Step: 150   Loss: 0.33831757\n",
            "Step: 200   Loss: 0.24838547\n",
            "Step: 250   Loss: 0.57618994\n",
            "Step: 300   Loss: 0.2964528\n",
            "Step: 350   Loss: 0.2665732\n",
            "Step: 400   Loss: 0.29460594\n",
            "Step: 450   Loss: 0.23399359\n",
            "Step: 500   Loss: 0.2070493\n",
            "Step: 550   Loss: 0.31179148\n",
            "Step: 600   Loss: 0.1148803\n",
            "Step: 650   Loss: 0.33535203\n",
            "Step: 700   Loss: 0.43505493\n",
            "Step: 750   Loss: 0.1802402\n",
            "Step: 800   Loss: 0.24920142\n",
            "Step: 850   Loss: 0.37071893\n",
            "Step: 900   Loss: 0.18913549\n",
            "Step: 950   Loss: 0.33932912\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s97fwEOoiXk3"
      },
      "source": [
        "## 6) Recurrent neural network\n",
        "\n",
        "\n",
        "*   Learn sequential data\n",
        "*   Ex. prediction of a word after a partial sentence, understanding of the current scene in a video based on previous scences\n",
        "\n",
        "![RNN cell](https://drive.google.com/uc?id=1hvEtbzjuT8hxBtNNTrBRMxthCcfFN5FG) \n",
        "출처: https://colah.github.io/posts/2015-08-Understanding-LSTMs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8p7tgEPijeSd"
      },
      "source": [
        "## 7) LSTM\n",
        "\n",
        "\n",
        "* Gradient vanishing problem: during backpropagation, as gradient is calculated by chain rule, the final grandient becomes almost zero\n",
        "* Long short-term memory: solves gradient vanishing problem and handles long-term dependencies\n",
        "![LSTM](https://drive.google.com/uc?id=1W9JKubIgJoyvzQy4U8KGNQWcVziu_6fT)\n",
        "출처: https://colah.github.io/posts/2015-08-Understanding-LSTMs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5hjLLUbrYwyO"
      },
      "source": [
        "\n",
        "\n",
        "Let's learn simple LSTM model for language modeling. The code comes from [TF-RNN tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn/ptb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vrmOgxLQDznW"
      },
      "source": [
        "# 2. Prepare PTB dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V5N1npMVQqJz"
      },
      "source": [
        "\n",
        "PTB is dataset widely used for natural language processing (NLP). It annotates syntactic or semantic label as a tree structure. A leaf node is matching to a word. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "EFZ3bfVsQz_p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "1adcf96c-db8a-447c-831d-48fa09cbb9af"
      },
      "source": [
        "#@title Click to download PTB\n",
        "!rm -rf data*\n",
        "!rm -rf simple-examples*\n",
        "!wget http://www.fit.vutbr.cz/%7Eimikolov/rnnlm/simple-examples.tgz\n",
        "!tar -xzf simple-examples.tgz\n",
        "!mv simple-examples/data ./"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-31 05:30:54--  http://www.fit.vutbr.cz/%7Eimikolov/rnnlm/simple-examples.tgz\n",
            "Resolving www.fit.vutbr.cz (www.fit.vutbr.cz)... 147.229.9.23, 2001:67c:1220:809::93e5:917\n",
            "Connecting to www.fit.vutbr.cz (www.fit.vutbr.cz)|147.229.9.23|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34869662 (33M) [application/x-gtar]\n",
            "Saving to: ‘simple-examples.tgz’\n",
            "\n",
            "simple-examples.tgz 100%[===================>]  33.25M  3.88MB/s    in 9.2s    \n",
            "\n",
            "2019-05-31 05:31:03 (3.63 MB/s) - ‘simple-examples.tgz’ saved [34869662/34869662]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XkCOptqMBcZB"
      },
      "source": [
        "Let's list up the files in the downloaded directory (`data`). Notice that a command beginning with `!`(exclamation mark) executes the shell command; in this case we will run `ls`, which *lists status* of a directory (or files)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FbKr7pdqe9cC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "157c5f9a-5725-496b-a10a-1a29587895ca"
      },
      "source": [
        "!ls data"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ptb.char.test.txt   ptb.char.valid.txt\tptb.train.txt  README\n",
            "ptb.char.train.txt  ptb.test.txt\tptb.valid.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mTvy_I4MCoJ2"
      },
      "source": [
        "## Define input preprocessing functions\n",
        "We provide utility functions to process the input files.\n",
        "* `_read_words(filename)`: creates a list of all words in the file (`filename`).\n",
        "* `_build_vocab(filename)`: assigns a unique ID to each word in the file (`filename`).\n",
        "* `_file_to_word_ids(filename, word_to_id)`: reads a file and converts each word with its *ID*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "drceRvn4VGec",
        "colab": {}
      },
      "source": [
        "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "\"\"\"Utilities for parsing PTB text files.\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import collections\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "Py3 = sys.version_info[0] == 3\n",
        "\n",
        "def _read_words(filename):\n",
        "  with tf.gfile.GFile(filename, \"r\") as f:\n",
        "    if Py3:\n",
        "      return f.read().replace(\"\\n\", \"<eos>\").split()\n",
        "    else:\n",
        "      return f.read().decode(\"utf-8\").replace(\"\\n\", \"<eos>\").split()\n",
        "\n",
        "\n",
        "def _build_vocab(filename):\n",
        "  data = _read_words(filename)\n",
        "\n",
        "  counter = collections.Counter(data)\n",
        "  count_pairs = sorted(counter.items(), key=lambda x: (-x[1], x[0]))\n",
        "\n",
        "  words, _ = list(zip(*count_pairs))\n",
        "  word_to_id = dict(zip(words, range(len(words))))\n",
        "\n",
        "  return word_to_id\n",
        "\n",
        "\n",
        "def _file_to_word_ids(filename, word_to_id):\n",
        "  data = _read_words(filename)\n",
        "  return [word_to_id[word] for word in data if word in word_to_id]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T1ae1U-WCIXj"
      },
      "source": [
        "Let's see how the files look like. We will use `_read_words()` function followed by `join` for parsing the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VI16OqyP4ou-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "74fead05-fda4-4231-b5f3-7c45d17d6890"
      },
      "source": [
        "train_words = _read_words('data/ptb.train.txt')\n",
        "print('Train set:', ', '.join(train_words[:100]))\n",
        "\n",
        "test_words = _read_words('data/ptb.test.txt')\n",
        "print('Test set:', ', '.join(test_words[:100]))\n",
        "\n",
        "valid_words = _read_words('data/ptb.valid.txt')\n",
        "print('Validate set:', ', '.join(valid_words[:100]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set: aer, banknote, berlitz, calloway, centrust, cluett, fromstein, gitano, guterman, hydro-quebec, ipo, kia, memotec, mlx, nahb, punts, rake, regatta, rubens, sim, snack-food, ssangyong, swapo, wachter, <eos>, pierre, <unk>, N, years, old, will, join, the, board, as, a, nonexecutive, director, nov., N, <eos>, mr., <unk>, is, chairman, of, <unk>, n.v., the, dutch, publishing, group, <eos>, rudolph, <unk>, N, years, old, and, former, chairman, of, consolidated, gold, fields, plc, was, named, a, nonexecutive, director, of, this, british, industrial, conglomerate, <eos>, a, form, of, asbestos, once, used, to, make, kent, cigarette, filters, has, caused, a, high, percentage, of, cancer, deaths, among, a, group, of\n",
            "Test set: no, it, was, n't, black, monday, <eos>, but, while, the, new, york, stock, exchange, did, n't, fall, apart, friday, as, the, dow, jones, industrial, average, plunged, N, points, most, of, it, in, the, final, hour, it, barely, managed, to, stay, this, side, of, chaos, <eos>, some, circuit, breakers, installed, after, the, october, N, crash, failed, their, first, test, traders, say, unable, to, cool, the, selling, panic, in, both, stocks, and, futures, <eos>, the, N, stock, specialist, firms, on, the, big, board, floor, the, buyers, and, sellers, of, last, resort, who, were, criticized, after, the, N, crash, once, again, could, n't\n",
            "Validate set: consumers, may, want, to, move, their, telephones, a, little, closer, to, the, tv, set, <eos>, <unk>, <unk>, watching, abc, 's, monday, night, football, can, now, vote, during, <unk>, for, the, greatest, play, in, N, years, from, among, four, or, five, <unk>, <unk>, <eos>, two, weeks, ago, viewers, of, several, nbc, <unk>, consumer, segments, started, calling, a, N, number, for, advice, on, various, <unk>, issues, <eos>, and, the, new, syndicated, reality, show, hard, copy, records, viewers, ', opinions, for, possible, airing, on, the, next, day, 's, show, <eos>, interactive, telephone, technology, has, taken, a, new, leap, in, <unk>, and, television, programmers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cnNhG69dgWsA"
      },
      "source": [
        "### Quiz 1\n",
        "Find the identifier of the word \"*market*\" using the defined functions above.\n",
        "\n",
        "**Hint**: use `_build_vocab()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QZyw665-gWsE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "574e8756-5904-4e89-8599-6bd39d58c99e"
      },
      "source": [
        "train_file = 'data/ptb.train.txt'\n",
        "word_to_id = _build_vocab(train_file)\n",
        "print(word_to_id['market'])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xrE4WkZNUn9o"
      },
      "source": [
        "## More input preprocessing functions\n",
        "\n",
        "* `ptb_raw_data(data_path)`: Returns `(train_data, valid_data, test_data, vocabulary)` by combining the utility functions above.\n",
        "* `ptb_producer(raw_data, batch_size, num_steps, name)`: For computational reasons, we will process data in mini-batches of size `batch_size`, Every word in a batch should correspond to a time t. TensorFlow will automatically sum the gradients of each batch for you.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZGKQAqtXBTbe",
        "colab": {}
      },
      "source": [
        "def ptb_raw_data(data_path=None):\n",
        "  \"\"\"Load PTB raw data from data directory \"data_path\".\n",
        "\n",
        "  Reads PTB text files, converts strings to integer ids,\n",
        "  and performs mini-batching of the inputs.\n",
        "\n",
        "  The PTB dataset comes from Tomas Mikolov's webpage:\n",
        "\n",
        "  http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz\n",
        "\n",
        "  Args:\n",
        "    data_path: string path to the directory where simple-examples.tgz has\n",
        "      been extracted.\n",
        "\n",
        "  Returns:\n",
        "    tuple (train_data, valid_data, test_data, vocabulary)\n",
        "    where each of the data objects can be passed to PTBIterator.\n",
        "  \"\"\"\n",
        "\n",
        "  train_path = os.path.join(data_path, \"ptb.train.txt\")\n",
        "  valid_path = os.path.join(data_path, \"ptb.valid.txt\")\n",
        "  test_path = os.path.join(data_path, \"ptb.test.txt\")\n",
        "\n",
        "  word_to_id = _build_vocab(train_path)\n",
        "  train_data = _file_to_word_ids(train_path, word_to_id)\n",
        "  valid_data = _file_to_word_ids(valid_path, word_to_id)\n",
        "  test_data = _file_to_word_ids(test_path, word_to_id)\n",
        "  vocabulary = len(word_to_id)\n",
        "  return train_data, valid_data, test_data, vocabulary\n",
        "\n",
        "\n",
        "def ptb_producer(raw_data, batch_size, num_steps, name=None):\n",
        "  \"\"\"Iterate on the raw PTB data.\n",
        "\n",
        "  This chunks up raw_data into batches of examples and returns Tensors that\n",
        "  are drawn from these batches.\n",
        "\n",
        "  Args:\n",
        "    raw_data: one of the raw data outputs from ptb_raw_data.\n",
        "    batch_size: int, the batch size.\n",
        "    num_steps: int, the number of unrolls.\n",
        "    name: the name of this operation (optional).\n",
        "\n",
        "  Returns:\n",
        "    A pair of Tensors, each shaped [batch_size, num_steps]. The second element\n",
        "    of the tuple is the same data time-shifted to the right by one.\n",
        "\n",
        "  Raises:\n",
        "    tf.errors.InvalidArgumentError: if batch_size or num_steps are too high.\n",
        "  \"\"\"\n",
        "  with tf.name_scope(name, \"PTBProducer\", [raw_data, batch_size, num_steps]):\n",
        "    raw_data = tf.convert_to_tensor(raw_data, name=\"raw_data\", dtype=tf.int32)\n",
        "\n",
        "    data_len = tf.size(raw_data)\n",
        "    batch_len = data_len // batch_size\n",
        "    data = tf.reshape(raw_data[0 : batch_size * batch_len],\n",
        "                      [batch_size, batch_len])\n",
        "\n",
        "    epoch_size = (batch_len - 1) // num_steps\n",
        "    assertion = tf.assert_positive(\n",
        "        epoch_size,\n",
        "        message=\"epoch_size == 0, decrease batch_size or num_steps\")\n",
        "    with tf.control_dependencies([assertion]):\n",
        "      epoch_size = tf.identity(epoch_size, name=\"epoch_size\")\n",
        "\n",
        "    i = tf.train.range_input_producer(epoch_size, shuffle=False).dequeue()\n",
        "    x = tf.strided_slice(data, [0, i * num_steps],\n",
        "                         [batch_size, (i + 1) * num_steps])\n",
        "    x.set_shape([batch_size, num_steps])\n",
        "    y = tf.strided_slice(data, [0, i * num_steps + 1],\n",
        "                         [batch_size, (i + 1) * num_steps + 1])\n",
        "    y.set_shape([batch_size, num_steps])\n",
        "    return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "piRAhFIGGRc_"
      },
      "source": [
        "### Quiz 2\n",
        "Guess how many words in x or y of `ptb_producer()` when \n",
        "**batch_size=2 and num_steps=5.**\n",
        "\n",
        "Then check it yourself.\n",
        "**HINT**\n",
        "* `x, y = ptb_producer(...)`\n",
        "* `x_, y_ = sess.run(...)`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X37jTic3HZM9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "2b7d4e31-c726-40e7-fede-567050861021"
      },
      "source": [
        "data_path='data'\n",
        "train_data, _, _, _ = ptb_raw_data(data_path)\n",
        "batch_size = 2\n",
        "num_steps = 5\n",
        "    \n",
        "with tf.Graph().as_default():    \n",
        "    x, y = ptb_producer(train_data, batch_size, num_steps, name=None)\n",
        "  \n",
        "    print('x', x)\n",
        "    print('y', y)\n",
        "    \n",
        "    sess = tf.Session()\n",
        "    tf.train.start_queue_runners(sess = sess)\n",
        "    \n",
        "    x_, y_ =  sess.run(x),sess.run(y)\n",
        "\n",
        "    print('x_', x_)\n",
        "    print('y_', y_)\n",
        "    "
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x Tensor(\"PTBProducer/StridedSlice:0\", shape=(2, 5), dtype=int32)\n",
            "y Tensor(\"PTBProducer/StridedSlice_1:0\", shape=(2, 5), dtype=int32)\n",
            "x_ [[9970 9971 9972 9974 9975]\n",
            " [1969    0   98   89 2254]]\n",
            "y_ [[9980 9981 9982 9983 9984]\n",
            " [ 312 1641    4 1063    8]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a4UKKwwsZa4I"
      },
      "source": [
        "# 3. Build RNN model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5zhtEo46Hatf"
      },
      "source": [
        "### Setting hyperparameters\n",
        "We provide a pre-defined configuration in `medium` scale; you can find other configurations at the [TF RNN tutorial](https://github.com/tensorflow/models/blob/master/tutorials/rnn/ptb/ptb_word_lm.py#L320)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "19MkDHgFHh5Y",
        "colab": {}
      },
      "source": [
        "class MediumConfig(object):\n",
        "  \"\"\"Medium config.\"\"\"\n",
        "  init_scale = 0.05   # the initial scale of the weights\n",
        "  learning_rate = 1.0 # the initial value of the learning rate\n",
        "  max_grad_norm = 5   # the maximum permissible norm of the gradient\n",
        "\n",
        "  num_layers = 2      # the number of LSTM layers\n",
        "  num_steps = 35      # the number of unrolled steps of LSTM\n",
        "  hidden_size = 650   # the number of LSTM units\n",
        "\n",
        "  max_epoch = 6       # the number of epochs trained with the initial learning rate\n",
        "  max_max_epoch = 39  # the total number of epochs for training\n",
        "  keep_prob = 0.5     # the probability of keeping weights in the dropout layer\n",
        "  lr_decay = 0.8      # the decay of the learning rate for each epoch after \"max_epoch\"\n",
        "  batch_size = 20     # the batch size \n",
        "  vocab_size = 10000  # the vocabulary size\n",
        "   \n",
        "config = MediumConfig()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M8UKfIQ8FdFy"
      },
      "source": [
        "### Word embeddings \n",
        "Convert word ids to vector representations by using `tf.nn.embedding_lookup`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wHJMzr9KFYvX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "09ba4011-de65-4fd4-b598-312e8e1a4d12"
      },
      "source": [
        "class PTBInput(object):\n",
        "    \"\"\"The input data.\"\"\"\n",
        "    def __init__(self, config, data, name=None):\n",
        "      self.batch_size = batch_size = config.batch_size\n",
        "      self.num_steps = num_steps = config.num_steps\n",
        "      self.epoch_size = ((len(data) // batch_size) - 1) // num_steps\n",
        "      self.input_data, self.targets = ptb_producer(\n",
        "          data, batch_size, num_steps, name=name)\n",
        "      \n",
        "def inputs(input):\n",
        "    embedding_size = config.hidden_size # LSTM의 은닉층의 수와 동일하게 \n",
        "    vocab_size = config.vocab_size\n",
        "    with tf.device(\"/cpu:0\"):\n",
        "      embedding = tf.get_variable(\n",
        "          \"embedding\", [vocab_size, embedding_size])\n",
        "      inputs = tf.nn.embedding_lookup(embedding, input.input_data)\n",
        "      return inputs\n",
        "  \n",
        "with tf.Graph().as_default():\n",
        "    data_path = 'data'\n",
        "    raw_data = ptb_raw_data(data_path)\n",
        "    train_data, valid_data, test_data, _ = raw_data\n",
        "    train_input = PTBInput(config=config, data=train_data, name=\"TrainInput\")\n",
        "    print(inputs(train_input))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"embedding_lookup/Identity:0\", shape=(20, 35, 650), dtype=float32, device=/device:CPU:0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sGJ_-LgwIige"
      },
      "source": [
        "### Quiz 3\n",
        "Guess the tensor shape of output of embedding lookup when reading embedding for wordIDs=[3, 9, 20] (vocab_size=100, embedding_size=4)\n",
        "\n",
        "Then check it yourself. \n",
        "What happens if wordIs=[3,9,200] if other conditions are the same?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ee8ZoxmXKgI8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "786e4b35-5562-4635-dd8a-703fa2fcbfe7"
      },
      "source": [
        "vocab_size = 100\n",
        "embedding_size = 4\n",
        "with tf.Graph().as_default():\n",
        "  wordIDs=tf.placeholder(dtype=tf.int32)\n",
        "   \n",
        "  embedding = tf.get_variable(\n",
        "      \"embedding\", [vocab_size, embedding_size])\n",
        "  \n",
        "  lookup = tf.nn.embedding_lookup(embedding, wordIDs)\n",
        "  \n",
        "  init = tf.global_variables_initializer()\n",
        "  sess = tf.Session()\n",
        "  sess.run(init)\n",
        "  \n",
        "  # Fill below\n",
        "  print(sess.run(lookup, feed_dict = {wordIDs:[3,9,20]}))\n",
        "  print(sess.run(lookup, feed_dict = {wordIDs:[3,9,200]}))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.14736399  0.01971614 -0.18641701  0.02163848]\n",
            " [ 0.166616    0.01221365  0.11983153  0.03308383]\n",
            " [-0.0332275  -0.155791    0.21573529  0.14656037]]\n",
            "[[ 0.14736399  0.01971614 -0.18641701  0.02163848]\n",
            " [ 0.166616    0.01221365  0.11983153  0.03308383]\n",
            " [ 0.          0.          0.          0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SWyh4MHCtgJ4"
      },
      "source": [
        "### Define RNN graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TOAEPevotxtT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "6aaf1f2c-6b4a-4cd2-ba9b-c4ea0c1d373a"
      },
      "source": [
        "def build_rnn_graph_lstm(inputs, config, is_training=True):\n",
        "    \"\"\"Build the inference graph using canonical LSTM cells.\"\"\"\n",
        "    def make_cell():\n",
        "      cell = tf.contrib.rnn.BasicLSTMCell(\n",
        "          config.hidden_size, forget_bias=0.0, state_is_tuple=True,\n",
        "          reuse=not is_training)\n",
        "      if is_training and config.keep_prob < 1:\n",
        "        cell = tf.contrib.rnn.DropoutWrapper(\n",
        "            cell, output_keep_prob=config.keep_prob)\n",
        "      return cell\n",
        "\n",
        "    # Stacking multiple LSTMs\n",
        "    cell = tf.contrib.rnn.MultiRNNCell(\n",
        "        [make_cell() for _ in range(config.num_layers)], state_is_tuple=True)\n",
        "\n",
        "    initial_state = cell.zero_state(config.batch_size, tf.float32)\n",
        "    state = initial_state\n",
        "    \n",
        "    # Simplified version of tf.nn.static_rnn().\n",
        "    # This builds an unrolled LSTM for tutorial purposes only.\n",
        "    outputs = []\n",
        "    with tf.variable_scope(\"RNN\"):\n",
        "      for time_step in range(config.num_steps):\n",
        "        if time_step > 0: tf.get_variable_scope().reuse_variables()\n",
        "        (cell_output, state) = cell(inputs[:, time_step, :], state)\n",
        "        outputs.append(cell_output)\n",
        "    output = tf.reshape(tf.concat(outputs, 1), [-1, config.hidden_size])\n",
        "    return output, state, initial_state\n",
        "  \n",
        "  \n",
        "with tf.Graph().as_default():\n",
        "    data_path = 'data'\n",
        "    raw_data = ptb_raw_data(data_path)\n",
        "    train_data, valid_data, test_data, _ = raw_data\n",
        "    train_input = PTBInput(config=config, data=train_data, name=\"TrainInput\")\n",
        "    inputs_ = inputs(train_input)\n",
        "    \n",
        "    output, final_state, initial_state = build_rnn_graph_lstm(inputs_, config)\n",
        "    print(output)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-51-fcdce9c45434>:6: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-51-fcdce9c45434>:14: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Tensor(\"Reshape:0\", shape=(700, 650), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9Vyd8rYE7JTv"
      },
      "source": [
        "### Define loss \n",
        "`tf.contrib.seq2seq.sequence_loss`: Weighted cross-entropy loss for a sequence of logits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JuTA70pg7Lnf",
        "colab": {}
      },
      "source": [
        "def loss(config, input_, output):\n",
        "  softmax_w = tf.get_variable(\n",
        "        \"softmax_w\", [config.hidden_size, config.vocab_size], tf.float32)\n",
        "  softmax_b = tf.get_variable(\"softmax_b\", [config.vocab_size], tf.float32)\n",
        "  logits = tf.nn.xw_plus_b(output, softmax_w, softmax_b)\n",
        "  # Reshape logits to be a 3-D tensor for sequence loss\n",
        "  logits = tf.reshape(logits, [config.batch_size, config.num_steps, config.vocab_size])\n",
        "\n",
        "  # Use the contrib sequence loss and average over the batches\n",
        "  loss = tf.contrib.seq2seq.sequence_loss(\n",
        "        logits,\n",
        "        input_.targets,\n",
        "        tf.ones([config.batch_size, config.num_steps], tf.float32),\n",
        "        average_across_timesteps=False,\n",
        "        average_across_batch=True)\n",
        "   \n",
        "  cost = tf.reduce_sum(loss)\n",
        "  return cost\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Lpb3sfKO7MA7"
      },
      "source": [
        "### Define optimizer(train_op)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "95L51-rZ7Oc-",
        "colab": {}
      },
      "source": [
        "def optimizer(cost):\n",
        "  tvars = tf.trainable_variables()\n",
        "  grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars),\n",
        "                                    config.max_grad_norm)\n",
        "  optimizer = tf.train.GradientDescentOptimizer(1.0)\n",
        "  train_op = optimizer.apply_gradients(\n",
        "        zip(grads, tvars),\n",
        "        global_step=tf.train.get_or_create_global_step())\n",
        "  return train_op"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MA_-1EhV8hSr"
      },
      "source": [
        "# 4. Run RNN model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iMiIbwC78j-E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "fd4d947d-4911-4aac-f6eb-6f00bc41f26a"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "def define_graph(config):\n",
        "  data_path = 'data'\n",
        "  raw_data = ptb_raw_data(data_path)\n",
        "  train_data, valid_data, test_data, _ = raw_data\n",
        "  train_input = PTBInput(config=config, data=train_data, name=\"TrainInput\")\n",
        "  initializer = tf.random_uniform_initializer(-config.init_scale,\n",
        "                                              config.init_scale)\n",
        "  with tf.variable_scope(\"Model\", reuse=None, initializer=initializer):\n",
        "      output, final_state, initial_state = build_rnn_graph_lstm(inputs(train_input), config)\n",
        "    \n",
        "      cost = loss(config, train_input, output)\n",
        "      train_op = optimizer(cost)\n",
        "  return cost, initial_state, final_state, train_op\n",
        "      \n",
        "def run(sess, cost, initial_state, final_state, train_op):\n",
        "  init = tf.global_variables_initializer()\n",
        "  tf.train.start_queue_runners(sess=sess)\n",
        "  sess.run(init)\n",
        "    \n",
        "  state = sess.run(initial_state)\n",
        "    \n",
        "  costs = 0.0\n",
        "  iters = 0\n",
        "  start_time = time.time()\n",
        "  for step in range(500):\n",
        "      feed_dict = {}\n",
        "      for i, (c, h) in enumerate(initial_state):\n",
        "        feed_dict[c] = state[i].c\n",
        "        feed_dict[h] = state[i].h\n",
        "      \n",
        "      cost_, state, _ = sess.run((cost, final_state, train_op), feed_dict=feed_dict)\n",
        "      costs += cost_\n",
        "      iters += config.num_steps\n",
        "      \n",
        "      if step % 50 == 0:\n",
        "         print(\"[step:%d] perplexity: %.3f   speed: %.0f word/sec\" %\n",
        "            (step, np.exp(costs / iters),\n",
        "             iters * config.batch_size /\n",
        "             (time.time() - start_time)))\n",
        "\n",
        "\n",
        "config =  MediumConfig()\n",
        "with tf.Graph().as_default():\n",
        "    cost, initial_state, final_state, train_op = define_graph(config)\n",
        "   \n",
        "    sess = tf.Session()\n",
        "    run(sess, cost, initial_state, final_state, train_op)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "[step:0] perplexity: 10016.832   speed: 1376 word/sec\n",
            "[step:50] perplexity: 1967.532   speed: 4732 word/sec\n",
            "[step:100] perplexity: 1412.284   speed: 4881 word/sec\n",
            "[step:150] perplexity: 1153.928   speed: 4927 word/sec\n",
            "[step:200] perplexity: 999.808   speed: 4953 word/sec\n",
            "[step:250] perplexity: 893.311   speed: 4970 word/sec\n",
            "[step:300] perplexity: 814.279   speed: 4984 word/sec\n",
            "[step:350] perplexity: 751.620   speed: 4995 word/sec\n",
            "[step:400] perplexity: 697.457   speed: 4998 word/sec\n",
            "[step:450] perplexity: 654.936   speed: 5003 word/sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C7FK5eg_4WCy"
      },
      "source": [
        "# 5. Visualize using TensorBoard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2_oD0_sK5hm6"
      },
      "source": [
        "### Preparation: Setting Up TensorBoard\n",
        "**NOTE**:  This setting is only for colab (you may not know the details).\n",
        "\n",
        "TensorBoard opens an HTTP endpoint that users can access to the UI. However, Colab is a system running on cloud servers that do not expose the machine's public IP address. `ngrok` is a service that opens a proxy server and makes the machine accessible via URL provided by it.\n",
        "\n",
        "If you use a standalone server (instead of colab), you can just use **'tensorboard --logdir=<logdir> --port=<port>'**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZcJ21Ydw6HPl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "9920da22-a196-4540-8700-3bf38d7371fd"
      },
      "source": [
        "#download and unzip ngrok\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-31 06:08:18--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.4.95.48, 34.196.237.103, 52.72.145.109, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.4.95.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16648024 (16M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab  79%[==============>     ]  12.67M  63.3MB/s               \rngrok-stable-linux- 100%[===================>]  15.88M  70.2MB/s    in 0.2s    \n",
            "\n",
            "2019-05-31 06:08:18 (70.2 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [16648024/16648024]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CH0DBF4S6KFB",
        "colab": {}
      },
      "source": [
        "#run tensorboard\n",
        "LOG_DIR = './log'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "#run ngrok\n",
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "trtXkJsH6i6i"
      },
      "source": [
        "### Visualize the graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0wZVf-XQPmax"
      },
      "source": [
        "TensorBoard provides a UI for rendering the NN graph to run. We need to write the defined graph by using `tf.summary.FileWriter`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AHqkk2Ha6oTq",
        "colab": {}
      },
      "source": [
        "config =  MediumConfig()\n",
        "with tf.Graph().as_default():\n",
        "    define_graph(config)\n",
        "    writer = tf.summary.FileWriter('./log', tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lNGfaIwPP8Z7"
      },
      "source": [
        "Let's get the public IP address and open the URL."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XrggWUhU64ji",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bc13723e-6d34-493e-e46c-51418b719f65"
      },
      "source": [
        "# Get the publicly accessible URL for TensorBoard\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://d3a9555e.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Dy-9kJge87po"
      },
      "source": [
        "## Visualize the perplexity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rgVD6KeM9Ig-",
        "colab": {}
      },
      "source": [
        "def run_with_summary(sess, cost, initial_state, final_state, train_op):\n",
        "  writer = tf.summary.FileWriter('./log', tf.get_default_graph())\n",
        "  init = tf.global_variables_initializer()\n",
        "  tf.train.start_queue_runners(sess=sess)\n",
        "  sess.run(init)\n",
        "    \n",
        "  state = sess.run(initial_state)\n",
        "    \n",
        "  costs = 0.0\n",
        "  iters = 0\n",
        "  start_time = time.time()\n",
        "  for step in range(1500):\n",
        "      feed_dict = {}\n",
        "      for i, (c, h) in enumerate(initial_state):\n",
        "        feed_dict[c] = state[i].c\n",
        "        feed_dict[h] = state[i].h\n",
        "      \n",
        "      cost_, state, _ = sess.run((cost, final_state, train_op), feed_dict=feed_dict)\n",
        "      costs += cost_\n",
        "      iters += config.num_steps\n",
        "      \n",
        "      #add summary\n",
        "      perplexity_summ = tf.Summary()\n",
        "      perplexity_summ.value.add(\n",
        "        tag='perplexity', simple_value=np.exp(costs/iters))\n",
        "      \n",
        "      writer.add_summary(perplexity_summ, step)\n",
        "      if step % 100 == 0:\n",
        "         print(\"[step:%d] perplexity: %.3f   speed: %.0f word/sec\" %\n",
        "            (step, np.exp(costs / iters),\n",
        "             iters * config.batch_size /\n",
        "             (time.time() - start_time)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JgEZ8t0L9DZc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "ce8a4bb7-6203-49c8-e7cc-11dd83a99d82"
      },
      "source": [
        "config =  MediumConfig()\n",
        "with tf.Graph().as_default():\n",
        "    cost, initial_state, final_state, train_op = define_graph(config)\n",
        "   \n",
        "    sess = tf.Session()\n",
        "    run_with_summary(sess, cost, initial_state, final_state, train_op)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[step:0] perplexity: 9972.362   speed: 1386 word/sec\n",
            "[step:100] perplexity: 1451.912   speed: 4903 word/sec\n",
            "[step:200] perplexity: 1028.920   speed: 4989 word/sec\n",
            "[step:300] perplexity: 833.964   speed: 5018 word/sec\n",
            "[step:400] perplexity: 709.987   speed: 5038 word/sec\n",
            "[step:500] perplexity: 626.509   speed: 5048 word/sec\n",
            "[step:600] perplexity: 567.043   speed: 5053 word/sec\n",
            "[step:700] perplexity: 519.573   speed: 5060 word/sec\n",
            "[step:800] perplexity: 478.507   speed: 5064 word/sec\n",
            "[step:900] perplexity: 446.803   speed: 5068 word/sec\n",
            "[step:1000] perplexity: 422.496   speed: 5072 word/sec\n",
            "[step:1100] perplexity: 398.944   speed: 5074 word/sec\n",
            "[step:1200] perplexity: 380.023   speed: 5076 word/sec\n",
            "[step:1300] perplexity: 362.717   speed: 5079 word/sec\n",
            "[step:1400] perplexity: 349.679   speed: 5080 word/sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5RpCO2VmR3JQ"
      },
      "source": [
        "Go back to the TensorBoard and check the `SCALARS` tab."
      ]
    }
  ]
}