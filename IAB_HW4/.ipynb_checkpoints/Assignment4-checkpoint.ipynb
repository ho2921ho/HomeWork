{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Session #2\n",
    "## ML-based SA by using Naive Bayes (assignment)\n",
    "\n",
    "\n",
    "수업 시간에 실습한 코드를 조금한 변형하여, positive, negative 두 가지 감정이 아닌 anger, joy, sad 3가지의 감정에 대해 분류하는 코드를 작성해 봅시다.\n",
    "\n",
    "대부분의 파트는 실습시간에 배운 것과 동일하지만, label이 3가지인만큼 dictionary를 사용해서 보다 효율적으로 코드를 작성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python 2 and 3 compatibility\n",
    "from __future__ import division, absolute_import, print_function, unicode_literals\n",
    "import six \n",
    "\n",
    "import io\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from os import listdir\n",
    "import math\n",
    "\n",
    "#-*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## variable 선언 부\n",
    "- 확률 계산 값을 저장할 변수 및 file path 를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "\n",
    "voca_dic = {}             # token dictionary\n",
    "\n",
    "emotions = ['anger','joy','sad'] # emotions candidate\n",
    "\n",
    "log_prior = {}\n",
    "log_likelihood = {}\n",
    "\n",
    "for emotion in emotions:\n",
    "    log_prior[emotion] = 1 # prior probability for each emotion\n",
    "    log_likelihood[emotion] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 1. Compute the prior probability\n",
    "- 각 class 의 (anger, joy, sad) prior 확률을 구해봅니다.\n",
    "- 본 실험에서는 file 의 개수를 count 하는 것으로 구해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "count # of files in class path\n",
    "Input: data path\n",
    "Output: # of data\n",
    "'''\n",
    "def count_file(dir_path):\n",
    "    list_files = [f for f in listdir(dir_path)]\n",
    "    return len(list_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사전 데이터와 테스트에 사용할 텍스트 파일이 있는 폴더를 지정합니다.  \n",
    "여기서는 코드 .ipynb 파일이 들어 있는 폴더 내,\n",
    "data 폴더 안에 학습 용 파일(폴더)가 들어 있는 것을 가정하였습니다. \n",
    "\n",
    "(만일 데이터 다른 폴더에 있을 경우 이를 변경하셔야 합니다.  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* log prior of the  anger class :  7.438971592395862\n",
      "* log prior of the  joy class :  7.38770923908104\n",
      "* log prior of the  sad class :  7.334981878871814\n"
     ]
    }
   ],
   "source": [
    "data_root_path = './data'\n",
    "\n",
    "target_data = data_root_path + '/emo_train/'\n",
    "# target_data = data_root_path + '/train'\n",
    "\n",
    "\n",
    "for emotion in emotions:\n",
    "    log_prior[emotion] =  math.log(count_file(target_data + emotion))\n",
    "\n",
    "for emotion in emotions:   \n",
    "    print('* log prior of the ', emotion ,'class : ', str(log_prior[emotion]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 2. Compute the Likelihood\n",
    "- 주어진 문장과 각 class 간 likelihood 값을 계산해 봅니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 2-1. Create Vocabulary Dictionary\n",
    "- 현재 data set 에서 사용되는 모든 token 을 파악하기 위해서 전체 data set 에 들어 있는 token 을 포함하는 dictionary 를 생성합니다.\n",
    "- 특정 폴더 안에 있는 포든 파일을 읽어서 해당 파일에 들어 있는 문장을 tokenize 후 얻어진 token 을 dictioinary 에 추가 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "build token dictionary\n",
    "Input: data path, 최종 dictionary\n",
    "Return: None (dictionary 는 내부에서 update 됨)\n",
    "'''\n",
    "def build_dic(dir_path, dic):\n",
    "    \n",
    "    list_files = [f for f in listdir(dir_path)]\n",
    "\n",
    "    for file in list_files:\n",
    "      \n",
    "        try:\n",
    "            f = open(dir_path + file, 'r',encoding='UTF8')\n",
    "            line = f.readline()  \n",
    "            tokens = word_tokenize(line.strip().lower())\n",
    "\n",
    "            for token in tokens:\n",
    "                if token not in dic:\n",
    "                    dic[token] = 1\n",
    "\n",
    "            f.close()        \n",
    "        \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "anger, joy, sad class 안에 들어 있는 모든 data 에서 token 을 추출하여 dictionary 를 완성 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* total voca size: 13505\n"
     ]
    }
   ],
   "source": [
    "for emotion in emotions:\n",
    "    build_dic(target_data + emotion + '/', voca_dic)\n",
    "    \n",
    "print(\"* total voca size: \" + str(len(voca_dic)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2-2. 각 Class 별 token 의 확률 table 생성\n",
    "- 특정 class 내 data 를 모두 tokenize 한 후 각 token 의 수를 count 하여 해당 token 이 해당 class 에서 나타날 확률을 계산합니다.\n",
    "- 확률 값 계산시 제외 되는 token 이 없게 하기 위해 전체 dictionary 를 기본으로 가진 후 추가 계산을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class 별 확률 table 생성\n",
    "Input: data path, 전체 dictionary\n",
    "Return: 해당 class 의 확률 테이블\n",
    "'''\n",
    "def create_class_dic(dir_path, base_dic):\n",
    "    \n",
    "    # copy base_dic and create likelihood_table\n",
    "    likelihood_table = {}\n",
    "    likelihood_table = dict( (nkey, 1) for nkey in [key for key in base_dic.keys()])\n",
    "        \n",
    "    list_files = [f for f in listdir(dir_path)]\n",
    "\n",
    "    for file in list_files:\n",
    "      \n",
    "        try:\n",
    "            f = open(dir_path + file, 'r',encoding='UTF8')\n",
    "            line = f.readline()  \n",
    "            tokens = word_tokenize(line.strip().lower())\n",
    "\n",
    "            for token in tokens:\n",
    "                \n",
    "                if token in likelihood_table:\n",
    "                    likelihood_table[token] = likelihood_table[token] + 1\n",
    "\n",
    "            f.close()     \n",
    "            \n",
    "        except Exception as e:\n",
    "            pinrt(e)\n",
    "            \n",
    "    return likelihood_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token = good\n",
      "# of tokens in anger class: \t30\n",
      "# of tokens in joy class: \t84\n",
      "# of tokens in sad class: \t46\n"
     ]
    }
   ],
   "source": [
    "table = {}\n",
    "for emotion in emotions:\n",
    "    table[emotion] = create_class_dic(target_data + emotion + '/', voca_dic)\n",
    "\n",
    "token = 'good'\n",
    "print('token = ' + token)\n",
    "print('# of tokens in anger class: \\t' + str(table['anger'][token]))\n",
    "print('# of tokens in joy class: \\t' + str(table['joy'][token]))\n",
    "print('# of tokens in sad class: \\t' + str(table['sad'][token]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2-3. 확률 table 을 log 확률 값으로 변환\n",
    "- log 함수는 monotonically increasing 함수이므로 log 를 취한 값으로 확률을 계산해도 동일한 비교가 가능합니다.\n",
    "- 확률값 계산시 * (곱셈) 이 아닌 + (덧셈) 으로 계산 가능하기 때문에 연산이 수월 합니다.\n",
    "- 곱셈으로 확률을 계산시 확률값이 매우 작아 질 경우 발생하는 수치에러를 방지할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "log likelihood table 연산\n",
    "Input: 특정 class 의 확률 테이블\n",
    "Return: # of data\n",
    "'''\n",
    "def compute_log_likelihood_table(class_table):\n",
    "    \n",
    "    new_table = {}\n",
    "    word_sum = sum(class_table.values())    \n",
    "    new_table = dict( (key, math.log((float)(value)/(float)(word_sum)) ) for (key, value) in six.iteritems(class_table))    \n",
    "    \n",
    "    return new_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token = good\n",
      "# of token in class: \t\t\t30\n",
      "probability of the token in class: \t0.0006640253214989265\n",
      "log probability: \t\t\t-7.358873360285843\n"
     ]
    }
   ],
   "source": [
    "for emotion in emotions:\n",
    "    log_likelihood[emotion] = compute_log_likelihood_table(table[emotion])\n",
    "\n",
    "\n",
    "token = 'good'\n",
    "print('token = ' + token)\n",
    "print('# of token in class: \\t\\t\\t' + str(table['anger'][token]))\n",
    "print('probability of the token in class: \\t' + str(table['anger'][token] / float(sum(table['joy'].values()))))\n",
    "print('log probability: \\t\\t\\t' + str(log_likelihood['anger'][token]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. 하나의 문서를 분류해 보세요\n",
    "\n",
    "- 클래스별 log_table 을 이용해서 classifier 를 구현해 보세요\n",
    "- anger, joy, sadness class 에 속할 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "특정 document 에 들어 있는 문장을 분류 (anger, joy, sadness)\n",
    "Input: document, prior 확률, likelihood 테이블\n",
    "Return: 클래스\n",
    "'''\n",
    "def classify_doc(document, log_prior, log_likelihood):\n",
    "    \n",
    "    prob = {}\n",
    "    for emotion in emotions:\n",
    "        prob[emotion] = 0\n",
    "    \n",
    "    tokens = word_tokenize(document.strip().lower())\n",
    "\n",
    "    for token in tokens:\n",
    "        \n",
    "        if token in log_likelihood['anger']:\n",
    "            prob['anger'] = prob['anger'] + log_likelihood['anger'][token]\n",
    "            \n",
    "        if token in log_likelihood['joy']:\n",
    "            prob['joy'] = prob['joy'] + log_likelihood['joy'][token]\n",
    "        \n",
    "        if token in log_likelihood['sad']:\n",
    "            prob['sad'] = prob['sad'] + log_likelihood['sad'][token]        \n",
    "        \n",
    "            \n",
    "    for emotion in emotions:\n",
    "        prob[emotion] += log_prior[emotion]\n",
    "    \n",
    "    result = max(prob, key=prob.get)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  input document  : \t@KevinHearne Oh! That actually was my first guess but... I thought he was too dark for an Irish man from BCE. Thanks for clearing it up :D\n",
      "  predicted class   : \tsad\n"
     ]
    }
   ],
   "source": [
    "# document = 'this is  my favorite. sooo exciting'\n",
    "document = '@KevinHearne Oh! That actually was my first guess but... I thought he was too dark for an Irish man from BCE. Thanks for clearing it up :D'\n",
    "\n",
    "ret = classify_doc(document, log_prior, log_likelihood)\n",
    "\n",
    "print('  input document  : \\t' + document)\n",
    "print('  predicted class   : \\t' + ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sad'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. 주어진 path 에 있는 모든 문서를 분류\n",
    "- 특정 폴더 안에 있는 모든 문서를 분류하고, 정확도를 측정해 본니다.\n",
    "- 주어진 폴더 안에는 같은 class 의 data 가 분류되어 들어 있습니다. \n",
    "- Train 시에 사용되지 않은 data 를 가지고 테스트를 해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "특정 폴더 안에 있는 모든 data 분류\n",
    "Input: data path\n",
    "Return: None\n",
    "'''\n",
    "def evaluate_all(dir_path):\n",
    "\n",
    "    list_files = [f for f in listdir(dir_path)]\n",
    "\n",
    "    cnt = {}\n",
    "    for emotion in emotions:\n",
    "        cnt[emotion] = 0\n",
    "\n",
    "    process_doc = 0\n",
    "\n",
    "    for file in list_files:\n",
    "        \n",
    "        try:\n",
    "            f = open(dir_path + file, 'r',encoding='UTF8')\n",
    "\n",
    "            ret = classify_doc(f.readline(), log_prior, log_likelihood)\n",
    "            process_doc += 1\n",
    "            f.close()\n",
    "\n",
    "        except Exception as e:\n",
    "            pinrt(e)\n",
    "        if ret is 'anger':\n",
    "            cnt['anger'] += 1\n",
    "        elif ret is 'joy':\n",
    "            cnt['joy'] += 1        \n",
    "        else:\n",
    "            cnt['sad'] += 1\n",
    "\n",
    "\n",
    "    print('* evaluate all document in ' + dir_path)\n",
    "    \n",
    "    print('## Target Emotion : ', dir_path[16:-1])\n",
    "    # 각자의 dir path에 따라서 이부분은 다를 수 있습니다\n",
    "    # anger와 같이 target emotion 이름이 출력되면 됩니다  \n",
    "    # ex) ## Target Emotion : anger\n",
    "    \n",
    "    for emotion in emotions:\n",
    "        print(emotion , 'probability: ' + str((float)(cnt[emotion]) / (float)(process_doc)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* evaluate all document in ./data/emo_test/anger/\n",
      "## Target Emotion :  anger\n",
      "anger probability: 0.5515463917525774\n",
      "joy probability: 0.13659793814432988\n",
      "sad probability: 0.3118556701030928\n",
      "\n",
      "\n",
      "* evaluate all document in ./data/emo_test/joy/\n",
      "## Target Emotion :  joy\n",
      "anger probability: 0.12758620689655173\n",
      "joy probability: 0.6103448275862069\n",
      "sad probability: 0.2620689655172414\n",
      "\n",
      "\n",
      "* evaluate all document in ./data/emo_test/sad/\n",
      "## Target Emotion :  sad\n",
      "anger probability: 0.36523929471032746\n",
      "joy probability: 0.1385390428211587\n",
      "sad probability: 0.49622166246851385\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for emotion in emotions:\n",
    "    \n",
    "    evaluate_all(data_root_path + '/emo_test/'+emotion+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger', 'joy', 'sad']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
