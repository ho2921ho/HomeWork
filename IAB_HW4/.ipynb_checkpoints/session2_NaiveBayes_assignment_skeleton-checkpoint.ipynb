{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Session #2\n",
    "## ML-based SA by using Naive Bayes (assignment)\n",
    "\n",
    "\n",
    "수업 시간에 실습한 코드를 조금한 변형하여, positive, negative 두 가지 감정이 아닌 anger, joy, sad 3가지의 감정에 대해 분류하는 코드를 작성해 봅시다.\n",
    "\n",
    "대부분의 파트는 실습시간에 배운 것과 동일하지만, label이 3가지인만큼 dictionary를 사용해서 보다 효율적으로 코드를 작성할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from os import listdir\n",
    "import math\n",
    "# python 2 and 3 compatibility\n",
    "from __future__ import division, absolute_import, print_function, unicode_literals\n",
    "import six \n",
    "\n",
    "#-*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## variable 선언 부\n",
    "- 확률 계산 값을 저장할 변수 및 file path 를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "\n",
    "voca_dic = {}             # token dictionary\n",
    "\n",
    "emotions = ['anger','joy','sad'] # emotions candidate\n",
    "\n",
    "log_prior = {}\n",
    "log_likelihood = {}\n",
    "\n",
    "for emotion in emotions:\n",
    "    log_prior[emotion] = 1 # prior probability for each emotion\n",
    "    log_likelihood[emotion] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 1. Compute the prior probability\n",
    "- 각 class 의 (anger, joy, sad) prior 확률을 구해봅니다.\n",
    "- 본 실험에서는 file 의 개수를 count 하는 것으로 구해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "count # of files in class path\n",
    "Input: data path\n",
    "Output: # of data\n",
    "'''\n",
    "def count_file(dir_path):\n",
    "    \n",
    "    '''\n",
    "    -- To DO -- \n",
    "    list files = ... \n",
    "    '''\n",
    "    \n",
    "    return len(list_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사전 데이터와 테스트에 사용할 텍스트 파일이 있는 폴더를 지정합니다.  \n",
    "여기서는 코드 .ipynb 파일이 들어 있는 폴더 내,\n",
    "data 폴더 안에 학습 용 파일(폴더)가 들어 있는 것을 가정하였습니다. \n",
    "\n",
    "(만일 데이터 다른 폴더에 있을 경우 이를 변경하셔야 합니다.  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* log prior of the  anger class :  1\n",
      "* log prior of the  joy class :  1\n",
      "* log prior of the  sad class :  1\n"
     ]
    }
   ],
   "source": [
    "data_root_path = './data'\n",
    "\n",
    "target_data = data_root_path + '/emo_train/'\n",
    "# target_data = data_root_path + '/train'\n",
    "\n",
    "\n",
    "for emotion in emotions:\n",
    "    '''\n",
    "    -- To DO --\n",
    "    각 emotion의 prior 값을 계산해봅시다\n",
    "    \n",
    "    log_prior[emotion] = ?\n",
    "    '''\n",
    "    \n",
    "for emotion in emotions:   \n",
    "    print('* log prior of the ', emotion ,'class : ', str(log_prior[emotion]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 2. Compute the Likelihood\n",
    "- 주어진 문장과 각 class 간 likelihood 값을 계산해 봅니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 2-1. Create Vocabulary Dictionary\n",
    "- 현재 data set 에서 사용되는 모든 token 을 파악하기 위해서 전체 data set 에 들어 있는 token 을 포함하는 dictionary 를 생성합니다.\n",
    "- 특정 폴더 안에 있는 포든 파일을 읽어서 해당 파일에 들어 있는 문장을 tokenize 후 얻어진 token 을 dictioinary 에 추가 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "build token dictionary\n",
    "Input: data path, 최종 dictionary\n",
    "Return: None (dictionary 는 내부에서 update 됨)\n",
    "'''\n",
    "def build_dic(dir_path, dic):\n",
    "    \n",
    "    list_files = [f for f in listdir(dir_path)]\n",
    "\n",
    "    for file in list_files:\n",
    "      \n",
    "        try:\n",
    "            f = open(dir_path + file, 'r')\n",
    "            '''\n",
    "            -- To DO -- \n",
    "            dir_path 내에 있는 파일들을 loop\n",
    "      \n",
    "            하나의 파일에 있는 내용을 읽은 후 tokenize\n",
    "            ex) tokens = word_tokenize(line.strip().lower())\n",
    "\n",
    "            tokens 에 담겨 있는 token 들을 dictionary 에 추가   \n",
    "            '''\n",
    "\n",
    "            f.close()        \n",
    "        \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "anger, joy, sad class 안에 들어 있는 모든 data 에서 token 을 추출하여 dictionary 를 완성 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emotion in emotions:\n",
    "    build_dic(target_data + emotion + '/', voca_dic)\n",
    "    \n",
    "print(\"* total voca size: \" + str(len(voca_dic)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2-2. 각 Class 별 token 의 확률 table 생성\n",
    "- 특정 class 내 data 를 모두 tokenize 한 후 각 token 의 수를 count 하여 해당 token 이 해당 class 에서 나타날 확률을 계산합니다.\n",
    "- 확률 값 계산시 제외 되는 token 이 없게 하기 위해 전체 dictionary 를 기본으로 가진 후 추가 계산을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class 별 확률 table 생성\n",
    "Input: data path, 전체 dictionary\n",
    "Return: 해당 class 의 확률 테이블\n",
    "'''\n",
    "def create_class_dic(dir_path, base_dic):\n",
    "    \n",
    "    # copy base_dic and create likelihood_table\n",
    "    likelihood_table = {}\n",
    "    likelihood_table = dict( (nkey, 1) for nkey in [key for key in base_dic.keys()])\n",
    "        \n",
    "    list_files = [f for f in listdir(dir_path)]\n",
    "\n",
    "    for file in list_files:\n",
    "      \n",
    "        try:\n",
    "            f = open(dir_path + file, 'r')\n",
    "            line = f.readline()  \n",
    "            tokens = word_tokenize(line.strip().lower())\n",
    "\n",
    "            for token in tokens:\n",
    "                '''\n",
    "                -- To DO -- \n",
    "                likelihood table 을 update\n",
    "                '''\n",
    "\n",
    "            f.close()     \n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    return likelihood_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {}\n",
    "for emotion in emotions:\n",
    "    table[emotion] = create_class_dic(target_data + emotion + '/', voca_dic)\n",
    "\n",
    "token = 'good'\n",
    "print('token = ' + token)\n",
    "print('# of tokens in anger class: \\t' + str(table['anger'][token]))\n",
    "print('# of tokens in joy class: \\t' + str(table['joy'][token]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2-3. 확률 table 을 log 확률 값으로 변환\n",
    "- log 함수는 monotonically increasing 함수이므로 log 를 취한 값으로 확률을 계산해도 동일한 비교가 가능합니다.\n",
    "- 확률값 계산시 * (곱셈) 이 아닌 + (덧셈) 으로 계산 가능하기 때문에 연산이 수월 합니다.\n",
    "- 곱셈으로 확률을 계산시 확률값이 매우 작아 질 경우 발생하는 수치에러를 방지할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "log likelihood table 연산\n",
    "Input: 특정 class 의 확률 테이블\n",
    "Return: # of data\n",
    "'''\n",
    "def compute_log_likelihood_table(class_table):\n",
    "    \n",
    "    new_table = {}\n",
    "    word_sum = sum(class_table.values())    \n",
    "    new_table = dict( (key, math.log((float)(value)/(float)(word_sum)) ) for (key, value) in six.iteritems(class_table))    \n",
    "    \n",
    "    return new_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emotion in emotions:\n",
    "    log_likelihood[emotion] = compute_log_likelihood_table(table[emotion])\n",
    "\n",
    "\n",
    "token = 'good'\n",
    "print('token = ' + token)\n",
    "print('# of token in class: \\t\\t\\t' + str(table['joy'][token]))\n",
    "print('probability of the token in class: \\t' + str(table['joy'][token] / float(sum(table['joy'].values()))))\n",
    "print('log probability: \\t\\t\\t' + str(log_likelihood['joy'][token]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. 하나의 문서를 분류해 보세요\n",
    "\n",
    "- 클래스별 log_table 을 이용해서 classifier 를 구현해 보세요\n",
    "- anger, joy, sadness class 에 속할 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "특정 document 에 들어 있는 문장을 분류 (anger, joy, sadness)\n",
    "Input: document, prior 확률, likelihood 테이블\n",
    "Return: 클래스\n",
    "'''\n",
    "def classify_doc(document, log_prior, log_likelihood):\n",
    "    \n",
    "    prob = {}\n",
    "    for emotion in emotions:\n",
    "        prob[emotion] = 0\n",
    "    \n",
    "    \n",
    "    tokens = word_tokenize(document.strip().lower())\n",
    "\n",
    "    for token in tokens:\n",
    "        '''\n",
    "        -- To DO -- \n",
    "        prob[emotion] 에 주어진 토큰의 해당 클래스에 따른 확률 값을 누적\n",
    "        '''\n",
    "    \n",
    "    for emotion in emotions:\n",
    "        prob[emotion] += log_prior[emotion]\n",
    "        \n",
    "        \n",
    "    \n",
    "    '''\n",
    "    -- To DO --\n",
    "    문서의 label을 3가지 중에 하나로 결정하여 result variable에 할당\n",
    "    '''    \n",
    "    result = 'joy'\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document = 'this is  my favorite. sooo exciting'\n",
    "document = 'i hate the move.. just waste of the time'\n",
    "\n",
    "ret = classify_doc(document, log_prior, log_likelihood)\n",
    "\n",
    "print('  input document  : \\t' + document)\n",
    "print('  predicted class   : \\t' + ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. 주어진 path 에 있는 모든 문서를 분류\n",
    "- 특정 폴더 안에 있는 모든 문서를 분류하고, 정확도를 측정해 본니다.\n",
    "- 주어진 폴더 안에는 같은 class 의 data 가 분류되어 들어 있습니다. \n",
    "- Train 시에 사용되지 않은 data 를 가지고 테스트를 해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "특정 폴더 안에 있는 모든 data 분류\n",
    "Input: data path\n",
    "Return: None\n",
    "'''\n",
    "def evaluate_all(dir_path):\n",
    "\n",
    "    list_files = [f for f in listdir(dir_path)]\n",
    "\n",
    "    cnt = {}\n",
    "    for emotion in emotions:\n",
    "        cnt[emotion] = 0\n",
    "\n",
    "    process_doc = 0\n",
    "\n",
    "    for file in list_files:\n",
    "\n",
    "        '''\n",
    "        -- To DO -- \n",
    "        파일을 읽은 후 위에서 작성한 classify_doc() 함수를 이용하여 class 를 분류\n",
    "        '''\n",
    "\n",
    "    print('* evaluate all document in ' + dir_path)\n",
    "    \n",
    "    print('## Target Emotion : ', dir_path[16:-1])\n",
    "    # 각자의 dir path에 따라서 이부분은 다를 수 있습니다\n",
    "    # anger와 같이 target emotion 이름이 출력되면 됩니다  \n",
    "    # ex) ## Target Emotion : anger\n",
    "    \n",
    "    for emotion in emotions:\n",
    "        print(emotion , 'probability: ' + str((float)(cnt[emotion]) / (float)(process_doc)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for emotion in emotions:\n",
    "    \n",
    "    evaluate_all(data_root_path + '/emo_test/'+emotion+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36torch041]",
   "language": "python",
   "name": "conda-env-py36torch041-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
