{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Session #2\n",
    "## ML-based SA by using Naive Bayes\n",
    "\n",
    "두 번째 세션에서는 Naive Bayes Calssifier 를 이용한 영어 텍스트 감성분석 프로그램을 작성해 봅니다. \n",
    "실습 수업은 프로그램의 주요 흐름을 설명하면서, TODO 처리된 핵심적인 부분의 코드를 직접 작성해보는 순서로 진행될 것입니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python 2 and 3 compatibility\n",
    "from __future__ import division, absolute_import, print_function, unicode_literals\n",
    "import six \n",
    "\n",
    "import io\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from os import listdir\n",
    "import math\n",
    "\n",
    "#-*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ykstyle/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download nltk package for word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## variable 선언 부\n",
    "- 확률 계산 값을 저장할 변수 및 file path 를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "\n",
    "voca_dic = {}             # token dictionary\n",
    "log_prior_pos = 1         # prior probability for positive class\n",
    "log_prior_neg = 1         # prior probability for negative class\n",
    "\n",
    "log_likelihood_pos = {}   \n",
    "log_likelihood_neg = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 1. Compute the prior probability\n",
    "- 각 class 의 (positive, negative) prior 확률을 구해봅니다.\n",
    "- training set 상에서 positive / negative class 에 속하는 data 의 개수를 count 하는 방법으로 구할 수 있습니다.\n",
    "- 본 실험에서는 file 의 개수를 count 하는 것으로 구해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "count # of files in class path\n",
    "Input: data path\n",
    "Output: # of data\n",
    "'''\n",
    "def count_file(dir_path):\n",
    "    list_files = [f for f in listdir(dir_path)]\n",
    "    return len(list_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사전 데이터와 테스트에 사용할 텍스트 파일이 있는 폴더를 지정합니다.  \n",
    "여기서는 코드 .ipynb 파일이 들어 있는 폴더 내,\n",
    "data 폴더 안에 학습 용 파일(폴더)가 들어 있는 것을 가정하였습니다. \n",
    "\n",
    "(만일 데이터 다른 폴더에 있을 경우 이를 변경하셔야 합니다.  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* log prior of the positive class: 9.433483923290392\n",
      "* log_prior of the negative class: 9.433483923290392\n"
     ]
    }
   ],
   "source": [
    "data_root_path = './data'\n",
    "\n",
    "#target_data = data_root_path + '/sample'\n",
    "target_data = data_root_path + '/train'\n",
    "\n",
    "log_prior_pos = math.log(count_file(target_data + '/pos'))\n",
    "log_prior_neg = math.log(count_file(target_data + '/neg'))\n",
    "\n",
    "print('* log prior of the positive class: ' + str(log_prior_pos))\n",
    "print('* log_prior of the negative class: ' + str(log_prior_neg ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step 2. Compute the Likelihood\n",
    "- 주어진 문장과 각 class 간 likelihood 값을 계산해 봅니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 2-1. Create Vocabulary Dictionary\n",
    "- 현재 data set 에서 사용되는 모든 token 을 파악하기 위해서 전체 data set 에 들어 있는 token 을 포함하는 dictionary 를 생성합니다.\n",
    "- 특정 폴더 안에 있는 포든 파일을 읽어서 해당 파일에 들어 있는 문장을 tokenize 후 얻어진 token 을 dictioinary 에 추가 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "build token dictionary\n",
    "Input: data path, 최종 dictionary\n",
    "Return: None (dictionary 는 내부에서 update 됨)\n",
    "'''\n",
    "def build_dic(dir_path, dic):\n",
    "    \n",
    "    list_files = [f for f in listdir(dir_path)]\n",
    "\n",
    "    for file in list_files:\n",
    "      \n",
    "        try:\n",
    "            f = open(dir_path + file, 'r')\n",
    "            line = f.readline()  \n",
    "            tokens = word_tokenize(line.strip().lower())\n",
    "\n",
    "            for token in tokens:\n",
    "                if token not in dic:\n",
    "                    dic[token] = 1\n",
    "\n",
    "            f.close()        \n",
    "        \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "positive, negative class 안에 들어 있는 모든 data 에서 token 을 추출하여 dictionary 를 완성 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* total voca size: 113962\n"
     ]
    }
   ],
   "source": [
    "build_dic(target_data + '/pos/', voca_dic)\n",
    "build_dic(target_data + '/neg/', voca_dic)\n",
    "print(\"* total voca size: \" + str(len(voca_dic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2-2. 각 Class 별 token 의 확률 table 생성\n",
    "- 특정 class 내 data 를 모두 tokenize 한 후 각 token 의 수를 count 하여 해당 token 이 해당 class 에서 나타날 확률을 계산합니다.\n",
    "- 확률 값 계산시 제외 되는 token 이 없게 하기 위해 전체 dictionary 를 기본으로 가진 후 추가 계산을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class 별 확률 table 생성\n",
    "Input: data path, 전체 dictionary\n",
    "Return: 해당 class 의 확률 테이블\n",
    "'''\n",
    "def create_class_dic(dir_path, base_dic):\n",
    "    \n",
    "    # copy base_dic and create likelihood_table\n",
    "    likelihood_table = {}\n",
    "    likelihood_table = dict( (nkey, 1) for nkey in base_dic.keys())\n",
    "        \n",
    "    list_files = [f for f in listdir(dir_path)]\n",
    "\n",
    "    for file in list_files:\n",
    "      \n",
    "        try:\n",
    "            f = open(dir_path + file, 'r')\n",
    "            line = f.readline()  \n",
    "            tokens = word_tokenize(line.strip().lower())\n",
    "\n",
    "            for token in tokens:\n",
    "                \n",
    "                if token in likelihood_table:\n",
    "                    likelihood_table[token] = likelihood_table[token] + 1\n",
    "\n",
    "            f.close()     \n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    return likelihood_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token = good\n",
      "# of tokens in positive class: \t7446\n",
      "# of tokens in negative class: \t7196\n"
     ]
    }
   ],
   "source": [
    "pos_table = create_class_dic(target_data + '/pos/', voca_dic)\n",
    "neg_table = create_class_dic(target_data + '/neg/', voca_dic)\n",
    "\n",
    "token = 'good'\n",
    "print('token = ' + token)\n",
    "print('# of tokens in positive class: \\t' + str(pos_table[token]))\n",
    "print('# of tokens in negative class: \\t' + str(neg_table[token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2-3. 확률 table 을 log 확률 값으로 변환\n",
    "- log 함수는 monotonically increasing 함수이므로 log 를 취한 값으로 확률을 계산해도 동일한 비교가 가능합니다.\n",
    "- 확률값 계산시 * (곱셈) 이 아닌 + (덧셈) 으로 계산 가능하기 때문에 연산이 수월 합니다.\n",
    "- 곱셈으로 확률을 계산시 확률값이 매우 작아 질 경우 발생하는 수치에러를 방지할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "log likelihood table 연산\n",
    "Input: 특정 class 의 확률 테이블\n",
    "Return: # of data\n",
    "'''\n",
    "def compute_log_likelihood_table(class_table):\n",
    "    \n",
    "    new_table = {}\n",
    "    word_sum = sum(class_table.values())    \n",
    "    new_table = dict( (key, math.log((float)(value)/(float)(word_sum)) ) for (key, value) in six.iteritems(class_table))    \n",
    "    \n",
    "    return new_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token = good\n",
      "# of token in class: \t\t\t7446\n",
      "probability of the token in class: \t0.002028817049256441\n",
      "log probability: \t\t\t-6.200302390140529\n"
     ]
    }
   ],
   "source": [
    "log_likelihood_pos = compute_log_likelihood_table(pos_table)\n",
    "log_likelihood_neg = compute_log_likelihood_table(neg_table)\n",
    "\n",
    "token = 'good'\n",
    "print('token = ' + token)\n",
    "print('# of token in class: \\t\\t\\t' + str(pos_table[token]))\n",
    "print('probability of the token in class: \\t' + str(pos_table[token] / float(sum(pos_table.values()))))\n",
    "print('log probability: \\t\\t\\t' + str(log_likelihood_pos[token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. 하나의 문서를 분류해 보세요\n",
    "\n",
    "- 클래스별 log_table 을 이용해서 classifier 를 구현해 보세요\n",
    "- positive class 에 속할 확률 vs negative class 에 속할 확률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "특정 document 에 들어 있는 문장을 분류 (positive/negative)\n",
    "Input: document, positive class prior 확률, negative class prior 확률, positive class likelihood 테이블, negative class likelihood 테이블\n",
    "Return: 클래스\n",
    "'''\n",
    "def classify_doc(document, log_prior_pos, log_prior_neg, log_likelihood_pos, log_likelihood_neg):\n",
    "    \n",
    "    pos_prob = 0\n",
    "    neg_prob = 0\n",
    "    \n",
    "    tokens = word_tokenize(document.strip().lower())\n",
    "\n",
    "    for token in tokens:\n",
    "\n",
    "        if token in log_likelihood_pos:\n",
    "            pos_prob = pos_prob + log_likelihood_pos[token]\n",
    "            \n",
    "        if token in log_likelihood_neg:\n",
    "            neg_prob = neg_prob + log_likelihood_neg[token]\n",
    "            \n",
    "    \n",
    "    pos_prob = pos_prob + log_prior_pos       \n",
    "    neg_prob = neg_prob + log_prior_neg\n",
    "    \n",
    "    if pos_prob > neg_prob:\n",
    "        return 'positive' \n",
    "    else:\n",
    "        return 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  input document  : \tthis is  my favorite. sooo exciting\n",
      "  predicted class   : \tpositive\n"
     ]
    }
   ],
   "source": [
    "document = 'this is  my favorite. sooo exciting'\n",
    "#document = 'i rainy day kkkk sad ugly '\n",
    "\n",
    "ret = classify_doc(document, log_prior_pos, log_prior_neg, log_likelihood_pos, log_likelihood_neg)\n",
    "\n",
    "print('  input document  : \\t' + document)\n",
    "print('  predicted class   : \\t' + ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. 주어진 path 에 있는 모든 문서를 분류\n",
    "- 특정 폴더 안에 있는 모든 문서를 분류하고, 정확도를 측정해 본니다.\n",
    "- 주어진 폴더 안에는 같은 class 의 data 가 분류되어 들어 있습니다. \n",
    "- Train 시에 사용되지 않은 data 를 가지고 테스트를 해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "특정 폴더 안에 있는 모든 data 분류\n",
    "Input: data path\n",
    "Return: None\n",
    "'''\n",
    "def evaluate_all(dir_path):\n",
    "\n",
    "    list_files = [f for f in listdir(dir_path)]\n",
    "\n",
    "    pos_cnt = 0\n",
    "    neg_cnt = 0\n",
    "    process_doc = 0\n",
    "\n",
    "    for file in list_files:\n",
    "\n",
    "        try:\n",
    "            f = open(dir_path + file, 'r')\n",
    "\n",
    "            ret = classify_doc(f.readline(), log_prior_pos, log_prior_neg, log_likelihood_pos, log_likelihood_neg)\n",
    "            process_doc += 1\n",
    "\n",
    "            f.close()\n",
    "\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "        if ret is 'positive':\n",
    "            pos_cnt += 1\n",
    "        else:\n",
    "            neg_cnt += 1\n",
    "\n",
    "    print('* evaluate all document in ' + dir_path)\n",
    "    print('  positive probability: ' + str((float)(pos_cnt) / (float)(process_doc)))\n",
    "    print('  negative probability: ' + str((float)(neg_cnt) / (float)(process_doc)))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* evaluate all document in ./data/test/neg/\n",
      "  positive probability: 0.12456\n",
      "  negative probability: 0.87544\n",
      "\n",
      "\n",
      "* evaluate all document in ./data/test/pos/\n",
      "  positive probability: 0.74336\n",
      "  negative probability: 0.25664\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_all(data_root_path + '/test/neg/')\n",
    "evaluate_all(data_root_path + '/test/pos/')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
